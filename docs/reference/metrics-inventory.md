# Metrics Inventory

## Overview

This document is the **one-stop reference** for all measurements in the Databricks Health Monitor platform. Each measurement is documented once, with columns indicating which method(s) can be used to access it.

### Reading This Document

| Column | Description |
|--------|-------------|
| **Measurement** | The business metric being measured |
| **Purpose** | What business question this metric answers |
| **TVF** | Table-Valued Function name (parameterized queries) |
| **Metric View** | Metric View name + measure (dashboard aggregates) |
| **Custom Metric** | Lakehouse Monitoring metric (time series analysis) |
| **Primary Use** | Recommended primary method for this metric |

### Legend

| Symbol | Meaning |
|--------|---------|
| âœ… | Available via this method |
| â¡ï¸ | Recommended primary method |
| â€” | Not available via this method |

---

## Summary Statistics

| Domain | Total Measurements | TVF | Metric View | Custom Metric |
|--------|-------------------|-----|-------------|---------------|
| ğŸ’° Cost | 67 | 38 | 42 | 35 |
| ğŸ”„ Reliability | 58 | 32 | 16 | 50 |
| âš¡ Performance (Query) | 52 | 28 | 18 | 46 |
| âš¡ Performance (Cluster) | 38 | 18 | 24 | 40 |
| ğŸ”’ Security | 28 | 24 | 12 | 13 |
| ğŸ“‹ Quality | 32 | 18 | 10 | 26 |
| **Total** | **275** | **158** | **122** | **210** |

> Note: Some measurements appear in multiple methods (e.g., success_rate is in all three), which is intentional as they serve different use cases.

---

## ğŸ’° COST DOMAIN

### Core Cost Metrics

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 1 | **Total Daily Cost** | Primary FinOps KPI for budgeting | `get_daily_cost_summary` | `mv_cost_analytics.total_cost` | `total_daily_cost` | â¡ï¸ Metric View |
| 2 | **Total DBUs** | Usage volume independent of pricing | `get_cost_trend_by_sku` | `mv_cost_analytics.total_dbu` | `total_daily_dbu` | â¡ï¸ Metric View |
| 3 | **Cost per DBU** | Unit economics / effective rate | `get_cost_efficiency_metrics` | `mv_cost_analytics.cost_per_dbu` | `avg_cost_per_dbu` | â¡ï¸ Metric View |
| 4 | **MTD Cost** | Month-to-date spending | â€” | `mv_cost_analytics.mtd_cost` | â€” | â¡ï¸ Metric View |
| 5 | **YTD Cost** | Year-to-date spending | â€” | `mv_cost_analytics.ytd_cost` | â€” | â¡ï¸ Metric View |
| 6 | **Projected Monthly Cost** | Budget forecasting | `get_cost_forecast` | `mv_commit_tracking.projected_monthly_cost` | â€” | â¡ï¸ Metric View |
| 7 | **Daily Burn Rate** | Daily cost average | â€” | `mv_commit_tracking.daily_avg_cost` | â€” | â¡ï¸ Metric View |
| 8 | **Day-over-Day Change %** | Daily cost variance | `get_daily_cost_summary.dod_change_pct` | `mv_cost_analytics.dod_cost_change_pct` | â€” | â¡ï¸ TVF |
| 9 | **Week-over-Week Growth %** | Weekly cost trend | â€” | `mv_cost_analytics.week_over_week_growth_pct` | â€” | â¡ï¸ Metric View |

### Cost Attribution & Breakdown

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 10 | **Top Cost Contributors** | Identify biggest spenders | `get_top_cost_contributors` | By dimension grouping | â€” | â¡ï¸ TVF |
| 11 | **Cost by Workspace** | Cross-workspace comparison | `get_workspace_cost_comparison` | Group by `workspace_name` | â€” | â¡ï¸ Metric View |
| 12 | **Cost by SKU** | Product mix analysis | `get_cost_trend_by_sku` | Group by `sku_name` | â€” | â¡ï¸ TVF |
| 13 | **Cost by Owner** | Chargeback attribution | `get_cost_by_owner` | Group by `owner` | â€” | â¡ï¸ TVF |
| 14 | **Cost by Tag** | Tag-based allocation | `get_cost_by_tag` | Group by `team_tag`, `project_tag` | â€” | â¡ï¸ TVF |
| 15 | **Cost by Cluster Type** | Infrastructure analysis | `get_cost_by_cluster_type` | â€” | â€” | â¡ï¸ TVF |
| 16 | **Storage Cost** | Storage billing analysis | `get_storage_cost_analysis` | â€” | â€” | â¡ï¸ TVF |
| 17 | **Job Cost Breakdown** | Cost per job | `get_job_cost_breakdown` | â€” | â€” | â¡ï¸ TVF |
| 18 | **Warehouse Cost** | SQL Warehouse spend | `get_warehouse_cost_analysis` | â€” | â€” | â¡ï¸ TVF |

### SKU-Specific Costs

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 19 | **Jobs Compute Cost** | Workflow automation spend | `get_cost_trend_by_sku('%JOBS%')` | Filter `sku_name` | `jobs_compute_cost` | â¡ï¸ Custom Metric |
| 20 | **SQL Compute Cost** | Analytics workload spend | `get_cost_trend_by_sku('%SQL%')` | Filter `sku_name` | `sql_compute_cost` | â¡ï¸ Custom Metric |
| 21 | **All-Purpose Cost** | Interactive compute spend | â€” | Filter `sku_name` | `all_purpose_cost` | â¡ï¸ Custom Metric |
| 22 | **Serverless Cost** | Modern compute spend | `get_serverless_vs_classic_cost` | Filter `is_serverless` | `serverless_cost` | â¡ï¸ Metric View |
| 23 | **DLT Cost** | Pipeline infrastructure spend | â€” | â€” | `dlt_cost` | â¡ï¸ Custom Metric |
| 24 | **Model Serving Cost** | ML serving spend | â€” | â€” | `model_serving_cost` | â¡ï¸ Custom Metric |
| 25 | **Jobs Cost Share %** | Workflow proportion | â€” | â€” | `jobs_cost_share` | â¡ï¸ Custom Metric |
| 26 | **SQL Cost Share %** | Analytics proportion | â€” | â€” | `sql_cost_share` | â¡ï¸ Custom Metric |
| 27 | **Serverless Ratio %** | Modern architecture adoption | â€” | `mv_cost_analytics.serverless_ratio` | `serverless_ratio` | â¡ï¸ Metric View |

### Tag Coverage & Governance

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 28 | **Tag Coverage %** | FinOps maturity KPI (>90%) | â€” | `mv_cost_analytics.tag_coverage_pct` | `tag_coverage_pct` | â¡ï¸ Metric View |
| 29 | **Tagged Cost Total** | Attributable spend | â€” | â€” | `tagged_cost_total` | â¡ï¸ Custom Metric |
| 30 | **Untagged Cost Total** | Unattributable spend | â€” | â€” | `untagged_cost_total` | â¡ï¸ Custom Metric |
| 31 | **Untagged Resources List** | Resources needing tags | `get_untagged_resources` | â€” | â€” | â¡ï¸ TVF |
| 32 | **Tagged Record Count** | Tag hygiene volume | â€” | â€” | `tagged_record_count` | â¡ï¸ Custom Metric |
| 33 | **Untagged Record Count** | Unattributed records | â€” | â€” | `untagged_record_count` | â¡ï¸ Custom Metric |

### Optimization Opportunities

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 34 | **Jobs on All-Purpose Cost** | Inefficient pattern (~40% overspend) | â€” | â€” | `jobs_on_all_purpose_cost` | â¡ï¸ Custom Metric |
| 35 | **Jobs on All-Purpose Count** | Optimization candidates | â€” | â€” | `jobs_on_all_purpose_count` | â¡ï¸ Custom Metric |
| 36 | **Potential Job Cluster Savings** | Actionable savings estimate | â€” | â€” | `potential_job_cluster_savings` | â¡ï¸ Custom Metric |
| 37 | **Jobs on All-Purpose Ratio** | Priority score | â€” | â€” | `jobs_on_all_purpose_ratio` | â¡ï¸ Custom Metric |

### Cost Anomalies & Drift

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 38 | **Cost Anomalies** | Cost spikes vs baseline | `get_cost_anomalies` | â€” | â€” | â¡ï¸ TVF |
| 39 | **Cost Drift %** | Period cost change (alert >10%) | â€” | â€” | `cost_drift_pct` | â¡ï¸ Custom Metric |
| 40 | **DBU Drift %** | Usage volume trend | â€” | â€” | `dbu_drift_pct` | â¡ï¸ Custom Metric |
| 41 | **Tag Coverage Drift** | FinOps maturity trend | â€” | â€” | `tag_coverage_drift` | â¡ï¸ Custom Metric |

### Data Quality (Cost Data)

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 42 | **Null SKU Count** | Data quality issue | â€” | â€” | `null_sku_count` | â¡ï¸ Custom Metric |
| 43 | **Null Price Count** | Billing data quality | â€” | â€” | `null_price_count` | â¡ï¸ Custom Metric |
| 44 | **Null SKU Rate %** | Data quality score (<1%) | â€” | â€” | `null_sku_rate` | â¡ï¸ Custom Metric |
| 45 | **Null Price Rate %** | Billing completeness (0%) | â€” | â€” | `null_price_rate` | â¡ï¸ Custom Metric |
| 46 | **Distinct Workspaces** | Platform utilization breadth | â€” | â€” | `distinct_workspaces` | â¡ï¸ Custom Metric |
| 47 | **Distinct SKUs** | Product mix indicator | â€” | â€” | `distinct_skus` | â¡ï¸ Custom Metric |
| 48 | **Record Count** | Data completeness | â€” | â€” | `record_count` | â¡ï¸ Custom Metric |

---

## ğŸ”„ RELIABILITY DOMAIN

### Core Reliability Metrics

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 49 | **Success Rate %** | Primary reliability KPI (>95%) | `get_job_success_rates.success_rate` | `mv_job_performance.success_rate` | `success_rate` | â¡ï¸ Metric View |
| 50 | **Failure Rate %** | Reliability issues indicator | `get_job_success_rates.failure_rate` | `mv_job_performance.failure_rate` | `failure_rate` | â¡ï¸ Metric View |
| 51 | **Total Runs** | Workload volume | `get_job_success_rates.total_runs` | `mv_job_performance.total_runs` | `total_runs` | â¡ï¸ Metric View |
| 52 | **Success Count** | Reliability numerator | â€” | â€” | `success_count` | â¡ï¸ Custom Metric |
| 53 | **Failure Count** | Issues requiring investigation | `get_failed_jobs_summary.failure_count` | `mv_job_performance.failures_today` | `failure_count` | â¡ï¸ Custom Metric |

### Failed Jobs Analysis

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 54 | **Failed Jobs List** | Actionable failure list | `get_failed_jobs_summary` | â€” | â€” | â¡ï¸ TVF |
| 55 | **Last Failure Time** | Recency of failure | `get_failed_jobs_summary.last_failure_time` | â€” | â€” | â¡ï¸ TVF |
| 56 | **Last Error Message** | Root cause hint | `get_failed_jobs_summary.last_error_message` | â€” | â€” | â¡ï¸ TVF |
| 57 | **Failure Patterns** | Error categorization | `get_job_failure_patterns` | â€” | â€” | â¡ï¸ TVF |
| 58 | **Job Failure Cost** | Cost of failures | `get_job_failure_cost` | â€” | â€” | â¡ï¸ TVF |

### Duration Metrics

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 59 | **Avg Duration (min)** | Performance baseline | `get_job_success_rates.avg_duration_min` | `mv_job_performance.avg_duration_minutes` | `avg_duration_minutes` | â¡ï¸ Metric View |
| 60 | **P50 Duration (min)** | Typical performance | `get_job_duration_percentiles.p50` | â€” | `p50_duration_minutes` | â¡ï¸ Custom Metric |
| 61 | **P90 Duration (min)** | Outlier threshold | `get_job_duration_percentiles.p90` | â€” | `p90_duration_minutes` | â¡ï¸ Custom Metric |
| 62 | **P95 Duration (min)** | SLA target threshold | `get_job_duration_percentiles.p95` | `mv_job_performance.p95_duration_minutes` | `p95_duration_minutes` | â¡ï¸ Metric View |
| 63 | **P99 Duration (min)** | Critical SLA threshold | `get_job_duration_percentiles.p99` | â€” | `p99_duration_minutes` | â¡ï¸ Custom Metric |
| 64 | **Max Duration (min)** | Worst-case performance | `get_job_duration_percentiles.max` | â€” | `max_duration_minutes` | â¡ï¸ TVF |
| 65 | **Min Duration (min)** | Best-case performance | â€” | â€” | `min_duration_minutes` | â¡ï¸ Custom Metric |
| 66 | **Total Duration (min)** | Compute time consumption | â€” | â€” | `total_duration_minutes` | â¡ï¸ Custom Metric |
| 67 | **Duration Std Dev** | Consistency indicator | â€” | â€” | `stddev_duration_minutes` | â¡ï¸ Custom Metric |
| 68 | **Duration CV** | Consistency score (lower=better) | â€” | â€” | `duration_cv` | â¡ï¸ Custom Metric |
| 69 | **Duration Skew Ratio** | Distribution skewness | â€” | â€” | `duration_skew_ratio` | â¡ï¸ Custom Metric |
| 70 | **Tail Ratio** | P99/P95 ratio | â€” | â€” | `tail_ratio` | â¡ï¸ Custom Metric |

### Duration Thresholds

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 71 | **Long Running Jobs (>60m)** | Optimization candidates | `get_long_running_jobs` | â€” | `long_running_count` | â¡ï¸ TVF |
| 72 | **Very Long Running Jobs (>4h)** | Resource-intensive jobs | â€” | â€” | `very_long_running_count` | â¡ï¸ Custom Metric |
| 73 | **Long Running Rate %** | Optimization opportunity | â€” | â€” | `long_running_rate` | â¡ï¸ Custom Metric |

### Duration Trends

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 74 | **Duration Trends** | Performance trending | `get_job_duration_trends` | â€” | â€” | â¡ï¸ TVF |
| 75 | **Duration Drift %** | Performance regression | â€” | â€” | `duration_drift_pct` | â¡ï¸ Custom Metric |
| 76 | **P99 Duration Drift %** | SLA compliance trend | â€” | â€” | `p99_duration_drift_pct` | â¡ï¸ Custom Metric |
| 77 | **Long Running Drift** | Performance degradation | â€” | â€” | `long_running_drift` | â¡ï¸ Custom Metric |

### Termination Analysis

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 78 | **Timeout Count** | Resource constraint issues | â€” | â€” | `timeout_count` | â¡ï¸ Custom Metric |
| 79 | **Cancelled Count** | Manual interventions | â€” | â€” | `cancelled_count` | â¡ï¸ Custom Metric |
| 80 | **Skipped Count** | Dependency issues | â€” | â€” | `skipped_count` | â¡ï¸ Custom Metric |
| 81 | **Upstream Failed Count** | Dependency chain failures | â€” | â€” | `upstream_failed_count` | â¡ï¸ Custom Metric |
| 82 | **User Cancelled Count** | Manual intervention freq | â€” | â€” | `user_cancelled_count` | â¡ï¸ Custom Metric |
| 83 | **Internal Error Count** | Platform stability | â€” | â€” | `internal_error_count` | â¡ï¸ Custom Metric |
| 84 | **Driver Error Count** | Code/config issues | â€” | â€” | `driver_error_count` | â¡ï¸ Custom Metric |
| 85 | **Timeout Rate %** | Resource constraint rate | â€” | â€” | `timeout_rate` | â¡ï¸ Custom Metric |
| 86 | **Cancellation Rate %** | Intervention frequency | â€” | â€” | `cancellation_rate` | â¡ï¸ Custom Metric |
| 87 | **Skipped Rate %** | Dependency issue rate | â€” | â€” | `skipped_rate` | â¡ï¸ Custom Metric |
| 88 | **Upstream Failed Rate %** | Chain health indicator | â€” | â€” | `upstream_failed_rate` | â¡ï¸ Custom Metric |

### Trigger & Schedule Analysis

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 89 | **Scheduled Runs** | Automated workload | â€” | By `trigger_type` | `scheduled_runs` | â¡ï¸ Metric View |
| 90 | **Manual Runs** | Ad-hoc workload | â€” | By `trigger_type` | `manual_runs` | â¡ï¸ Custom Metric |
| 91 | **Retry Runs** | Recovery activity | â€” | By `trigger_type` | `retry_runs` | â¡ï¸ Custom Metric |
| 92 | **Scheduled Ratio %** | Automation maturity (>80%) | â€” | â€” | `scheduled_ratio` | â¡ï¸ Custom Metric |
| 93 | **Schedule Drift** | Jobs not on schedule | `get_job_schedule_drift` | â€” | â€” | â¡ï¸ TVF |

### SLA & Retry Analysis

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 94 | **SLA Compliance %** | SLA tracking | `get_job_sla_compliance.sla_compliance_pct` | â€” | â€” | â¡ï¸ TVF |
| 95 | **Runs Within SLA** | SLA-compliant runs | `get_job_sla_compliance.runs_within_sla` | â€” | â€” | â¡ï¸ TVF |
| 96 | **Runs Breaching SLA** | SLA violations | `get_job_sla_compliance.runs_breaching_sla` | â€” | â€” | â¡ï¸ TVF |
| 97 | **Retry Effectiveness %** | Recovery success rate | `get_job_retry_analysis.retry_effectiveness_pct` | â€” | â€” | â¡ï¸ TVF |
| 98 | **Wasted Compute (min)** | Failure compute cost | `get_job_retry_analysis.wasted_compute_min` | â€” | â€” | â¡ï¸ TVF |
| 99 | **Repair Rate %** | Retry activity level | â€” | â€” | `repair_rate` | â¡ï¸ Custom Metric |
| 100 | **Repair Cost Analysis** | Cost of repairs | `get_repair_cost_analysis` | â€” | â€” | â¡ï¸ TVF |

### Pipeline Health

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 101 | **Pipeline Health** | DLT pipeline status | `get_pipeline_health` | â€” | â€” | â¡ï¸ TVF |
| 102 | **Pipeline Success Rate** | DLT reliability | `get_pipeline_health.success_rate` | â€” | â€” | â¡ï¸ TVF |

### Reliability Drift

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 103 | **Success Rate Drift** | Reliability trend | â€” | â€” | `success_rate_drift` | â¡ï¸ Custom Metric |
| 104 | **Failure Count Drift** | Problem emergence | â€” | â€” | `failure_count_drift` | â¡ï¸ Custom Metric |
| 105 | **Run Count Drift %** | Workload trend | â€” | â€” | `run_count_drift_pct` | â¡ï¸ Custom Metric |
| 106 | **Duration CV Drift** | Consistency trend | â€” | â€” | `duration_cv_drift` | â¡ï¸ Custom Metric |

---

## âš¡ PERFORMANCE DOMAIN - QUERY

### Query Volume & Reliability

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 107 | **Query Count** | Query workload volume | `get_query_volume_trends.query_count` | `mv_query_performance.total_queries` | `query_count` | â¡ï¸ Metric View |
| 108 | **Successful Queries** | Reliability numerator | â€” | â€” | `successful_queries` | â¡ï¸ Custom Metric |
| 109 | **Failed Queries** | Query failures | `get_query_error_analysis` | â€” | `failed_queries` | â¡ï¸ TVF |
| 110 | **Cancelled Queries** | User interventions | â€” | â€” | `cancelled_queries` | â¡ï¸ Custom Metric |
| 111 | **Query Success Rate %** | Query reliability KPI | â€” | â€” | `query_success_rate` | â¡ï¸ Custom Metric |
| 112 | **Query Failure Rate %** | Query reliability issues | â€” | â€” | `query_failure_rate` | â¡ï¸ Custom Metric |
| 113 | **Distinct Users** | User base size | `get_top_users_by_query_count` | â€” | `distinct_users` | â¡ï¸ TVF |
| 114 | **Distinct Warehouses** | Warehouse usage | â€” | â€” | `distinct_warehouses` | â¡ï¸ Custom Metric |

### Query Latency

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 115 | **Avg Duration (sec)** | Performance baseline | `get_query_latency_percentiles.avg` | `mv_query_performance.avg_duration_seconds` | `avg_duration_sec` | â¡ï¸ Metric View |
| 116 | **P50 Duration (sec)** | Typical performance | `get_query_latency_percentiles.p50` | â€” | `p50_duration_sec` | â¡ï¸ Custom Metric |
| 117 | **P95 Duration (sec)** | SLA threshold | `get_query_latency_percentiles.p95` | `mv_query_performance.p95_duration_seconds` | `p95_duration_sec` | â¡ï¸ Metric View |
| 118 | **P99 Duration (sec)** | Worst-case | `get_query_latency_percentiles.p99` | `mv_query_performance.p99_duration_seconds` | `p99_duration_sec` | â¡ï¸ Metric View |
| 119 | **Max Duration (sec)** | Extreme outlier | `get_query_latency_percentiles.max` | â€” | `max_duration_sec` | â¡ï¸ TVF |
| 120 | **Total Duration (sec)** | Total query time | â€” | â€” | `total_duration_sec` | â¡ï¸ Custom Metric |

### Slow Queries

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 121 | **Slow Query List** | Optimization candidates | `get_slow_queries` | â€” | â€” | â¡ï¸ TVF |
| 122 | **Slow Query Count (>5m)** | Slow query volume | â€” | â€” | `slow_query_count` | â¡ï¸ Custom Metric |
| 123 | **Very Slow Query Count (>15m)** | Critical slow queries | â€” | â€” | `very_slow_query_count` | â¡ï¸ Custom Metric |
| 124 | **Slow Query Rate %** | Slow query proportion | â€” | â€” | `slow_query_rate` | â¡ï¸ Custom Metric |
| 125 | **SLA Breach Count (>60s)** | SLA violations | â€” | â€” | `sla_breach_count` | â¡ï¸ Custom Metric |
| 126 | **SLA Breach Rate %** | SLA compliance | â€” | â€” | `sla_breach_rate` | â¡ï¸ Custom Metric |

### Queue & Capacity

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 127 | **Queue Time Analysis** | Queue patterns | `get_query_queue_analysis` | â€” | â€” | â¡ï¸ TVF |
| 128 | **Avg Queue Time (sec)** | Capacity indicator | `get_query_queue_analysis.avg_queue_time` | â€” | `avg_queue_time_sec` | â¡ï¸ Custom Metric |
| 129 | **Total Queue Time (sec)** | Cumulative wait | â€” | â€” | `total_queue_time_sec` | â¡ï¸ Custom Metric |
| 130 | **High Queue Count** | Queue >10% of duration | â€” | â€” | `high_queue_count` | â¡ï¸ Custom Metric |
| 131 | **High Queue Rate %** | Capacity issues rate | â€” | â€” | `high_queue_rate` | â¡ï¸ Custom Metric |
| 132 | **Severe Queue Count** | Queue >30% of duration | â€” | â€” | `high_queue_severe_count` | â¡ï¸ Custom Metric |
| 133 | **Severe Queue Rate %** | Severe capacity rate | â€” | â€” | `severe_queue_rate` | â¡ï¸ Custom Metric |

### Efficiency & Cache

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 134 | **Efficient Query Count** | No spill, low queue, <60s | â€” | â€” | `efficient_query_count` | â¡ï¸ Custom Metric |
| 135 | **Efficiency Rate %** | Query efficiency KPI | â€” | â€” | `efficiency_rate` | â¡ï¸ Custom Metric |
| 136 | **Cache Hit Count** | Result cache hits | â€” | â€” | `cache_hit_count` | â¡ï¸ Custom Metric |
| 137 | **Cache Hit Rate %** | Cache efficiency | â€” | `mv_query_performance.cache_hit_rate` | `cache_hit_rate` | â¡ï¸ Metric View |

### Memory & Spill

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 138 | **Spill Analysis** | Memory pressure queries | `get_spill_analysis` | â€” | â€” | â¡ï¸ TVF |
| 139 | **Queries with Spill** | Memory pressure count | â€” | â€” | `queries_with_spill` | â¡ï¸ Custom Metric |
| 140 | **Total Spilled Bytes** | Spill volume | â€” | â€” | `total_spilled_bytes` | â¡ï¸ Custom Metric |
| 141 | **Spill Rate %** | Memory pressure rate | â€” | `mv_query_performance.spill_rate` | `spill_rate` | â¡ï¸ Metric View |

### I/O & Data Access

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 142 | **Total Bytes Read (TB)** | IO efficiency | â€” | â€” | `total_bytes_read_tb` | â¡ï¸ Custom Metric |
| 143 | **Total Rows Read (B)** | Data access volume | â€” | â€” | `total_rows_read_b` | â¡ï¸ Custom Metric |
| 144 | **Avg Bytes per Query** | Query scope | â€” | â€” | `avg_bytes_per_query` | â¡ï¸ Custom Metric |
| 145 | **Avg Compilation (sec)** | Parse efficiency | â€” | â€” | `avg_compilation_sec` | â¡ï¸ Custom Metric |
| 146 | **Complex Query Count** | Query >5000 chars | â€” | â€” | `complex_query_count` | â¡ï¸ Custom Metric |
| 147 | **Complex Query Rate %** | Complexity proportion | â€” | â€” | `complex_query_rate` | â¡ï¸ Custom Metric |

### Warehouse Utilization

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 148 | **Warehouse Utilization** | Warehouse efficiency | `get_warehouse_utilization` | â€” | â€” | â¡ï¸ TVF |
| 149 | **Scaling Events** | Auto-scaling activity | `get_warehouse_scaling_events` | â€” | â€” | â¡ï¸ TVF |
| 150 | **Query Cost by User** | User cost attribution | `get_query_cost_by_user` | â€” | â€” | â¡ï¸ TVF |

### Query Performance Drift

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 151 | **P95 Duration Drift %** | Performance trend | â€” | â€” | `p95_duration_drift_pct` | â¡ï¸ Custom Metric |
| 152 | **P99 Duration Drift %** | Worst-case trend | â€” | â€” | `p99_duration_drift_pct` | â¡ï¸ Custom Metric |
| 153 | **Query Volume Drift %** | Usage trend | â€” | â€” | `query_volume_drift_pct` | â¡ï¸ Custom Metric |
| 154 | **Failure Rate Drift** | Reliability trend | â€” | â€” | `failure_rate_drift` | â¡ï¸ Custom Metric |
| 155 | **Spill Rate Drift** | Memory pressure trend | â€” | â€” | `spill_rate_drift` | â¡ï¸ Custom Metric |
| 156 | **SLA Breach Rate Drift** | Compliance trend | â€” | â€” | `sla_breach_rate_drift` | â¡ï¸ Custom Metric |
| 157 | **Efficiency Rate Drift** | Optimization trend | â€” | â€” | `efficiency_rate_drift` | â¡ï¸ Custom Metric |

---

## âš¡ PERFORMANCE DOMAIN - CLUSTER

### Cluster Resource Metrics

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 158 | **Cluster Utilization** | Resource utilization | `get_cluster_utilization` | â€” | â€” | â¡ï¸ TVF |
| 159 | **Avg CPU User %** | User CPU utilization | â€” | â€” | `avg_cpu_user_pct` | â¡ï¸ Custom Metric |
| 160 | **Avg CPU System %** | System CPU | â€” | â€” | `avg_cpu_system_pct` | â¡ï¸ Custom Metric |
| 161 | **Avg CPU Wait %** | IO wait time | â€” | â€” | `avg_cpu_wait_pct` | â¡ï¸ Custom Metric |
| 162 | **Max CPU %** | Peak CPU | â€” | â€” | `max_cpu_*` | â¡ï¸ Custom Metric |
| 163 | **P95 CPU Total %** | CPU SLA threshold | â€” | â€” | `p95_cpu_total_pct` | â¡ï¸ Custom Metric |
| 164 | **Avg CPU Utilization %** | Overall CPU | `get_cluster_utilization.avg_cpu_pct` | `mv_cluster_utilization.avg_cpu_utilization` | â€” | â¡ï¸ Metric View |
| 165 | **Avg Memory %** | Memory utilization | `get_cluster_utilization.avg_memory_pct` | `mv_cluster_utilization.avg_memory_utilization` | `avg_memory_pct` | â¡ï¸ Metric View |
| 166 | **Max Memory %** | Peak memory | â€” | â€” | `max_memory_pct` | â¡ï¸ Custom Metric |
| 167 | **P95 Memory %** | Memory SLA threshold | â€” | â€” | `p95_memory_pct` | â¡ï¸ Custom Metric |
| 168 | **Avg Swap %** | Swap usage (bad) | â€” | â€” | `avg_swap_pct` | â¡ï¸ Custom Metric |

### Network Metrics

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 169 | **Network Sent (GB)** | Egress volume | â€” | â€” | `total_network_sent_gb` | â¡ï¸ Custom Metric |
| 170 | **Network Received (GB)** | Ingress volume | â€” | â€” | `total_network_received_gb` | â¡ï¸ Custom Metric |
| 171 | **Avg Network Throughput** | Network efficiency | â€” | â€” | `avg_network_*` | â¡ï¸ Custom Metric |

### Right-Sizing & Optimization

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 172 | **Underutilized Clusters** | Low utilization | `get_underutilized_clusters` | â€” | â€” | â¡ï¸ TVF |
| 173 | **Underutilized Hours** | Wasted time | â€” | â€” | `underutilized_hours` | â¡ï¸ Custom Metric |
| 174 | **Overutilized Hours** | Capacity issues | â€” | â€” | `overutilized_hours` | â¡ï¸ Custom Metric |
| 175 | **Optimal Util Hours** | Right-sized time | â€” | â€” | `optimal_util_hours` | â¡ï¸ Custom Metric |
| 176 | **CPU Saturation Hours** | CPU bottleneck | â€” | â€” | `cpu_saturation_hours` | â¡ï¸ Custom Metric |
| 177 | **CPU Idle Hours** | Wasted CPU | â€” | â€” | `cpu_idle_hours` | â¡ï¸ Custom Metric |
| 178 | **Underutilization Rate %** | Wasted proportion | â€” | â€” | `underutilization_rate` | â¡ï¸ Custom Metric |
| 179 | **Overutilization Rate %** | Capacity issue rate | â€” | â€” | `overutilization_rate` | â¡ï¸ Custom Metric |
| 180 | **Rightsizing Opportunity %** | Potential savings | â€” | â€” | `rightsizing_opportunity_pct` | â¡ï¸ Custom Metric |
| 181 | **Cluster Rightsizing Recs** | Specific recommendations | `get_cluster_rightsizing` | â€” | â€” | â¡ï¸ TVF |
| 182 | **Cluster Cost Efficiency** | Cost per compute | `get_cluster_cost_efficiency` | â€” | â€” | â¡ï¸ TVF |

### Cluster Efficiency (Metric Views)

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 183 | **Efficiency Score** | Composite metric 0-100 | â€” | `mv_cluster_efficiency.efficiency_score` | `efficiency_score` | â¡ï¸ Metric View |
| 184 | **Idle Percentage %** | CPU <10% time | â€” | `mv_cluster_efficiency.idle_percentage` | â€” | â¡ï¸ Metric View |
| 185 | **Wasted Hours** | Idle node hours | â€” | `mv_cluster_utilization.wasted_hours` | â€” | â¡ï¸ Metric View |
| 186 | **Potential Savings %** | Estimated savings | â€” | `mv_cluster_utilization.potential_savings_pct` | â€” | â¡ï¸ Metric View |
| 187 | **Underutilized Cluster Count** | Problem cluster count | â€” | `mv_cluster_efficiency.underutilized_cluster_count` | â€” | â¡ï¸ Metric View |
| 188 | **Idle Node Hours Total** | Total wasted hours | â€” | `mv_cluster_efficiency.idle_node_hours_total` | â€” | â¡ï¸ Metric View |

### Node Metrics

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 189 | **Node Hour Count** | Infrastructure scale | â€” | â€” | `node_hour_count` | â¡ï¸ Custom Metric |
| 190 | **Distinct Nodes** | Node diversity | â€” | â€” | `distinct_nodes` | â¡ï¸ Custom Metric |
| 191 | **Distinct Clusters** | Cluster count | â€” | â€” | `distinct_clusters` | â¡ï¸ Custom Metric |
| 192 | **Driver Node Count** | Driver nodes | â€” | â€” | `driver_node_count` | â¡ï¸ Custom Metric |
| 193 | **Worker Node Count** | Worker nodes | â€” | â€” | `worker_node_count` | â¡ï¸ Custom Metric |

### Compute Optimization TVFs

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 194 | **Jobs Without Autoscaling** | Autoscaling candidates | `get_jobs_without_autoscaling` | â€” | â€” | â¡ï¸ TVF |
| 195 | **Jobs on Legacy DBR** | DBR upgrade candidates | `get_jobs_on_legacy_dbr` | â€” | â€” | â¡ï¸ TVF |

### Cluster Drift

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 196 | **CPU Utilization Drift** | CPU trend | â€” | â€” | `cpu_utilization_drift` | â¡ï¸ Custom Metric |
| 197 | **Memory Utilization Drift** | Memory trend | â€” | â€” | `memory_utilization_drift` | â¡ï¸ Custom Metric |
| 198 | **Efficiency Score Drift** | Efficiency trend | â€” | â€” | `efficiency_score_drift` | â¡ï¸ Custom Metric |

---

## ğŸ”’ SECURITY DOMAIN

### User Activity

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 199 | **User Activity Summary** | User activity overview | `get_user_activity_summary` | â€” | â€” | â¡ï¸ TVF |
| 200 | **Total Events** | Activity volume | `get_user_activity_summary.total_events` | `mv_security_events.total_events` | `total_events` | â¡ï¸ Metric View |
| 201 | **Distinct Users** | User base size | â€” | `mv_security_events.unique_users` | `distinct_users` | â¡ï¸ Metric View |
| 202 | **Activity Patterns** | Time-based patterns | `get_user_activity_patterns` | â€” | â€” | â¡ï¸ TVF |
| 203 | **Events per User** | Activity level | â€” | â€” | `events_per_user` | â¡ï¸ Custom Metric |

### Authentication

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 204 | **Failed Access Attempts** | Auth failures list | `get_failed_access_attempts` | â€” | â€” | â¡ï¸ TVF |
| 205 | **Failed Auth Count** | Security incidents | `get_failed_access_attempts.failure_count` | `mv_security_events.failed_events` | `failed_auth_count` | â¡ï¸ Custom Metric |
| 206 | **Failed Auth Rate %** | Security risk (>1%) | â€” | â€” | `failed_auth_rate` | â¡ï¸ Custom Metric |
| 207 | **Auth Failure Drift** | Security posture trend | â€” | â€” | `auth_failure_drift` | â¡ï¸ Custom Metric |

### Privileged Activity

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 208 | **Permission Changes** | Permission audit trail | `get_permission_changes` | â€” | â€” | â¡ï¸ TVF |
| 209 | **Sensitive Actions** | Privileged operations | â€” | â€” | `sensitive_actions` | â¡ï¸ Custom Metric |
| 210 | **Sensitive Events (24h)** | Recent sensitive activity | â€” | `mv_security_events.sensitive_events_24h` | â€” | â¡ï¸ Metric View |
| 211 | **Admin Actions** | Admin activity | â€” | â€” | `admin_actions` | â¡ï¸ Custom Metric |
| 212 | **Admin Action Rate %** | Privileged proportion | â€” | â€” | `admin_action_rate` | â¡ï¸ Custom Metric |
| 213 | **Data Access Events** | Read operations | â€” | â€” | `data_access_events` | â¡ï¸ Custom Metric |
| 214 | **Service Account Activity** | Automation audit | `get_service_account_activity` | â€” | â€” | â¡ï¸ TVF |

### Data Access Audit

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 215 | **Table Access Audit** | Table access patterns | `get_table_access_audit` | â€” | â€” | â¡ï¸ TVF |
| 216 | **Sensitive Data Access** | PII table access | `get_sensitive_data_access` | â€” | â€” | â¡ï¸ TVF |
| 217 | **Data Export Events** | Download tracking | `get_data_export_events` | â€” | â€” | â¡ï¸ TVF |

### Anomaly & Risk

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 218 | **Unusual Access Patterns** | Anomaly detection | `get_unusual_access_patterns` | â€” | â€” | â¡ï¸ TVF |
| 219 | **User Risk Scores** | Risk assessment | `get_user_risk_scores` | â€” | â€” | â¡ï¸ TVF |
| 220 | **Event Growth Rate %** | Activity trend | â€” | `mv_security_events.event_growth_rate` | â€” | â¡ï¸ Metric View |

### Governance (Lineage)

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 221 | **Read Events** | Read operation counts | â€” | `mv_governance_analytics.read_events` | â€” | â¡ï¸ Metric View |
| 222 | **Write Events** | Write operation counts | â€” | `mv_governance_analytics.write_events` | â€” | â¡ï¸ Metric View |
| 223 | **Active Table Count** | Tables accessed (30d) | â€” | `mv_governance_analytics.active_table_count` | â€” | â¡ï¸ Metric View |
| 224 | **Inactive Table Count** | Stale tables | â€” | `mv_governance_analytics.inactive_table_count` | â€” | â¡ï¸ Metric View |

---

## ğŸ“‹ QUALITY DOMAIN

### Data Freshness

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 225 | **Table Freshness** | When last updated | `get_table_freshness` | â€” | â€” | â¡ï¸ TVF |
| 226 | **Stale Tables List** | Tables not updated | `get_stale_tables` | â€” | â€” | â¡ï¸ TVF |
| 227 | **Freshness by Domain** | Portfolio freshness | `get_data_freshness_by_domain` | â€” | â€” | â¡ï¸ TVF |
| 228 | **Freshness Rate %** | Tables <24h old | â€” | `mv_data_quality.freshness_rate` | â€” | â¡ï¸ Metric View |
| 229 | **Staleness Rate %** | Tables >48h old | â€” | `mv_data_quality.staleness_rate` | â€” | â¡ï¸ Metric View |
| 230 | **Fresh Tables Count** | Fresh table count | â€” | `mv_data_quality.fresh_tables` | â€” | â¡ï¸ Metric View |
| 231 | **Stale Tables Count** | Stale table count | â€” | `mv_data_quality.stale_tables` | `tables_with_issues` | â¡ï¸ Metric View |
| 232 | **Avg Hours Since Update** | Average table age | â€” | `mv_data_quality.avg_hours_since_update` | `avg_freshness_hours` | â¡ï¸ Metric View |
| 233 | **Freshness Violations** | Data currency issues | â€” | â€” | `freshness_violations` | â¡ï¸ Custom Metric |

### Data Quality Scores

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 234 | **Total Tables** | Quality scope | â€” | â€” | `total_tables` | â¡ï¸ Custom Metric |
| 235 | **Tables with Issues** | Quality problems | â€” | â€” | `tables_with_issues` | â¡ï¸ Custom Metric |
| 236 | **Avg Quality Score** | Overall quality (0-100) | â€” | â€” | `avg_quality_score` | â¡ï¸ Custom Metric |
| 237 | **Quality Score Below Threshold** | Tables <80 score | â€” | â€” | `quality_score_below_threshold` | â¡ï¸ Custom Metric |
| 238 | **Null Violation Count** | Completeness issues | â€” | â€” | `null_violation_count` | â¡ï¸ Custom Metric |
| 239 | **Schema Drift Count** | Schema changes | â€” | â€” | `schema_drift_count` | â¡ï¸ Custom Metric |
| 240 | **Quality Issue Rate %** | Quality coverage | â€” | â€” | `quality_issue_rate` | â¡ï¸ Custom Metric |
| 241 | **Quality Drift** | Quality trend | â€” | â€” | `quality_drift` | â¡ï¸ Custom Metric |

### Data Lineage

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 242 | **Lineage Summary** | Upstream/downstream deps | `get_data_lineage_summary` | â€” | â€” | â¡ï¸ TVF |
| 243 | **Orphan Tables** | Tables with no access | `get_orphan_tables` | â€” | â€” | â¡ï¸ TVF |

### Governance Coverage

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 244 | **Governance Compliance** | Tag compliance | `get_governance_compliance` | â€” | â€” | â¡ï¸ TVF |
| 245 | **Table Ownership Report** | Ownership metadata | `get_table_ownership_report` | â€” | â€” | â¡ï¸ TVF |
| 246 | **Total Assets** | Governance scope | â€” | â€” | `total_assets` | â¡ï¸ Custom Metric |
| 247 | **Documented Assets** | Documentation coverage | â€” | â€” | `documented_assets` | â¡ï¸ Custom Metric |
| 248 | **Tagged Assets** | Tagging coverage | â€” | â€” | `tagged_assets` | â¡ï¸ Custom Metric |
| 249 | **Access Controlled Assets** | Security coverage | â€” | â€” | `access_controlled_assets` | â¡ï¸ Custom Metric |
| 250 | **Lineage Tracked Assets** | Provenance coverage | â€” | â€” | `lineage_tracked_assets` | â¡ï¸ Custom Metric |
| 251 | **Documentation Rate %** | Doc coverage (>80%) | â€” | â€” | `documentation_rate` | â¡ï¸ Custom Metric |
| 252 | **Tagging Rate %** | Tag coverage (>90%) | â€” | â€” | `tagging_rate` | â¡ï¸ Custom Metric |
| 253 | **Access Control Rate %** | Security coverage (100%) | â€” | â€” | `access_control_rate` | â¡ï¸ Custom Metric |
| 254 | **Lineage Coverage Rate %** | Provenance (>70%) | â€” | â€” | `lineage_coverage_rate` | â¡ï¸ Custom Metric |
| 255 | **Governance Score** | Composite maturity (0-100) | â€” | â€” | `governance_score` | â¡ï¸ Custom Metric |
| 256 | **Governance Drift** | Maturity trend | â€” | â€” | `governance_drift` | â¡ï¸ Custom Metric |

### ML Anomaly Detection

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 257 | **Total Predictions** | ML coverage | â€” | `mv_ml_intelligence.total_predictions` | â€” | â¡ï¸ Metric View |
| 258 | **Anomaly Count** | Flagged anomalies | â€” | `mv_ml_intelligence.anomaly_count` | â€” | â¡ï¸ Metric View |
| 259 | **Anomaly Rate %** | Anomaly proportion | â€” | `mv_ml_intelligence.anomaly_rate` | â€” | â¡ï¸ Metric View |
| 260 | **Avg Anomaly Score** | Average score (0-1) | â€” | `mv_ml_intelligence.avg_anomaly_score` | â€” | â¡ï¸ Metric View |
| 261 | **High Risk Count** | Score â‰¥0.7 | â€” | `mv_ml_intelligence.high_risk_count` | â€” | â¡ï¸ Metric View |
| 262 | **Critical Count** | Score â‰¥0.9 | â€” | `mv_ml_intelligence.critical_count` | â€” | â¡ï¸ Metric View |
| 263 | **Anomaly Cost** | Cost of anomalies | â€” | `mv_ml_intelligence.anomaly_cost` | â€” | â¡ï¸ Metric View |

---

## ğŸ¤– ML INFERENCE DOMAIN

### Request Volume & Reliability

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 264 | **Total Requests** | ML serving volume | â€” | â€” | `total_requests` | â¡ï¸ Custom Metric |
| 265 | **Successful Requests** | ML reliability numerator | â€” | â€” | `successful_requests` | â¡ï¸ Custom Metric |
| 266 | **Failed Requests** | ML reliability issues | â€” | â€” | `failed_requests` | â¡ï¸ Custom Metric |
| 267 | **Request Success Rate %** | ML reliability KPI (>99%) | â€” | â€” | `request_success_rate` | â¡ï¸ Custom Metric |
| 268 | **Error Rate %** | ML reliability issues (<1%) | â€” | â€” | `error_rate` | â¡ï¸ Custom Metric |

### Latency

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 269 | **Avg Latency (ms)** | ML performance baseline | â€” | â€” | `avg_latency_ms` | â¡ï¸ Custom Metric |
| 270 | **P50 Latency (ms)** | Typical ML performance | â€” | â€” | `p50_latency_ms` | â¡ï¸ Custom Metric |
| 271 | **P95 Latency (ms)** | ML SLA threshold | â€” | â€” | `p95_latency_ms` | â¡ï¸ Custom Metric |
| 272 | **P99 Latency (ms)** | Worst-case ML performance | â€” | â€” | `p99_latency_ms` | â¡ï¸ Custom Metric |

### Throughput & Tokens

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 273 | **Throughput per Second** | ML capacity utilization | â€” | â€” | `throughput_per_second` | â¡ï¸ Custom Metric |
| 274 | **Total Tokens** | LLM usage volume | â€” | â€” | `total_tokens` | â¡ï¸ Custom Metric |
| 275 | **Avg Tokens per Request** | Request complexity | â€” | â€” | `avg_tokens_per_request` | â¡ï¸ Custom Metric |

### Drift

| # | Measurement | Purpose | TVF | Metric View | Custom Metric | Primary Use |
|---|-------------|---------|-----|-------------|---------------|-------------|
| 276 | **Latency Drift %** | ML performance trend | â€” | â€” | `latency_drift_pct` | â¡ï¸ Custom Metric |
| 277 | **Error Rate Drift** | ML reliability trend | â€” | â€” | `error_rate_drift` | â¡ï¸ Custom Metric |

---

## ğŸ¤– ML Model Integration (25 Models)

### ML Model to Metric Mapping

Each ML model in the platform enhances specific metrics with predictive capabilities:

| Domain | ML Model | Enhances Metric | Prediction Table | Question Type |
|--------|----------|----------------|------------------|---------------|
| **ğŸ’° Cost** | `cost_anomaly_detector` | Cost Anomalies (#38) | `cost_anomaly_predictions` | "Flag unusual spending" |
| **ğŸ’° Cost** | `budget_forecaster` | Projected Monthly Cost (#6) | `cost_forecast_predictions` | "Forecast next month's cost" |
| **ğŸ’° Cost** | `job_cost_optimizer` | Optimization Savings (#34-37) | `migration_recommendations` | "Where can we save money?" |
| **ğŸ’° Cost** | `chargeback_attribution` | Cost by Owner (#13) | â€” | "Allocate cost to teams" |
| **ğŸ’° Cost** | `commitment_recommender` | Projected Cost (#6) | `budget_alert_predictions` | "Recommend commitment level" |
| **ğŸ’° Cost** | `tag_recommender` | Tag Coverage (#28) | `tag_recommendations` | "Suggest tags for resources" |
| **ğŸ”„ Reliability** | `job_failure_predictor` | Failure Rate (#50) | `job_failure_predictions` | "Which jobs will fail?" |
| **ğŸ”„ Reliability** | `job_duration_forecaster` | Duration (#59-70) | `job_duration_predictions` | "How long will job take?" |
| **ğŸ”„ Reliability** | `sla_breach_predictor` | SLA Compliance (#94-96) | `incident_impact_predictions` | "Will SLA breach occur?" |
| **ğŸ”„ Reliability** | `pipeline_health_scorer` | Pipeline Health (#101-102) | `pipeline_health_scores` | "Rate pipeline health" |
| **ğŸ”„ Reliability** | `retry_success_predictor` | Retry Effectiveness (#97) | `retry_success_predictions` | "Will retry succeed?" |
| **âš¡ Performance** | `query_performance_forecaster` | P99 Duration (#118) | `query_optimization_recommendations` | "Predict query latency" |
| **âš¡ Performance** | `warehouse_optimizer` | Warehouse Utilization (#148) | `cluster_capacity_recommendations` | "Optimize warehouse size" |
| **âš¡ Performance** | `cache_hit_predictor` | Cache Hit Rate (#137) | `cache_hit_predictions` | "Predict cache performance" |
| **âš¡ Performance** | `cluster_sizing_recommender` | Cluster Efficiency (#183) | `cluster_rightsizing_recommendations` | "Right-size clusters" |
| **âš¡ Performance** | `cluster_capacity_planner` | Utilization (#164-165) | `cluster_capacity_recommendations` | "Plan capacity needs" |
| **âš¡ Performance** | `regression_detector` | Duration Drift (#75-77) | â€” | "Detect performance regression" |
| **âš¡ Performance** | `query_optimization_recommender` | Slow Queries (#121-126) | `query_optimization_classifications` | "How to optimize queries?" |
| **ğŸ”’ Security** | `security_threat_detector` | Unusual Access (#218) | `access_anomaly_predictions` | "Detect security threats" |
| **ğŸ”’ Security** | `access_pattern_analyzer` | Activity Patterns (#202) | `access_classifications` | "Classify access patterns" |
| **ğŸ”’ Security** | `compliance_risk_classifier` | Risk Scores (#219) | `user_risk_scores` | "Assess compliance risk" |
| **ğŸ”’ Security** | `permission_recommender` | Permission Changes (#208) | â€” | "Recommend permission changes" |
| **ğŸ“‹ Quality** | `data_drift_detector` | Quality Drift (#241) | `quality_anomaly_predictions` | "Detect data drift" |
| **ğŸ“‹ Quality** | `schema_change_predictor` | Schema Drift (#239) | `quality_trend_predictions` | "Predict schema changes" |
| **ğŸ“‹ Quality** | `schema_evolution_predictor` | Schema Drift (#239) | `freshness_alert_predictions` | "Predict evolution patterns" |

### ML Prediction Output Reference

| Prediction Table | Key Output Columns | Threshold for Action |
|------------------|-------------------|---------------------|
| `cost_anomaly_predictions` | `anomaly_score`, `is_anomaly` | `is_anomaly = 1` or `anomaly_score < -0.5` |
| `cost_forecast_predictions` | `predicted_cost`, `confidence_interval` | When `actual > predicted * 1.2` |
| `job_failure_predictions` | `failure_probability`, `will_fail` | `failure_probability > 0.5` |
| `job_duration_predictions` | `predicted_duration_sec` | When `actual > predicted * 1.5` |
| `access_anomaly_predictions` | `threat_score`, `is_threat` | `is_threat = 1` or `threat_score < -0.5` |
| `user_risk_scores` | `risk_level` (1-5) | `risk_level >= 4` |
| `quality_anomaly_predictions` | `drift_score`, `is_drifted` | `is_drifted = 1` |
| `pipeline_health_scores` | `health_score` (0-100) | `health_score < 70` |
| `cluster_rightsizing_recommendations` | `recommended_action`, `potential_savings` | Any recommendation |
| `query_optimization_recommendations` | `optimization_flags` | Any flag = 1 |

### When to Use ML Models vs Other Methods

| Question Type | Use ML Model? | Alternative | Example |
|---------------|---------------|-------------|---------|
| **"Will X happen?"** | âœ… Yes | â€” | "Will this job fail?" â†’ `job_failure_predictions` |
| **"Predict future X"** | âœ… Yes | â€” | "What's next month's cost?" â†’ `cost_forecast_predictions` |
| **"Is this anomalous?"** | âœ… Yes | Custom Metrics for simple drift | "Unusual spending?" â†’ `cost_anomaly_predictions` |
| **"Recommend action"** | âœ… Yes | TVF for simple lists | "How to optimize?" â†’ `query_optimization_recommendations` |
| **"Score/Risk level"** | âœ… Yes | â€” | "User risk score?" â†’ `user_risk_scores` |
| **"What is current X?"** | âŒ No | Metric View | "Total cost today?" â†’ `mv_cost_analytics` |
| **"List top N"** | âŒ No | TVF | "Top 10 slow queries?" â†’ `get_slow_queries` |
| **"Is X trending up/down?"** | âŒ No | Custom Metrics | "Is cost increasing?" â†’ `_drift_metrics` |

---

## Appendix: Method Comparison

### When to Use Each Method

| Method | Best For | Example Query |
|--------|----------|---------------|
| **TVF** | Parameterized investigation, actionable lists | "Top 10 cost drivers this week" |
| **Metric View** | Dashboard aggregates, current state KPIs | "What's the success rate?" |
| **Custom Metric** | Time series analysis, drift detection, alerting | "Is success rate degrading?" |
| **ML Model** | Predictions, anomaly detection, recommendations | "Will this job fail?" |

### Method Capabilities

| Capability | TVF | Metric View | Custom Metric | ML Model |
|------------|:---:|:-----------:|:-------------:|:--------:|
| Date range filtering | âœ… | Limited | âŒ | âœ… |
| Top N results | âœ… | âŒ | âŒ | âœ… |
| Custom thresholds | âœ… | âŒ | âŒ | âŒ |
| Dimension grouping | âŒ | âœ… | âŒ | Limited |
| Pre-formatted output | âŒ | âœ… | âŒ | âœ… |
| Time series tracking | âŒ | âŒ | âœ… | âŒ |
| Drift detection | âŒ | âŒ | âœ… | âœ… |
| Automated alerting | âŒ | âŒ | âœ… | âœ… |
| Statistical profiling | âŒ | âŒ | âœ… | âŒ |
| Future predictions | âŒ | âŒ | âŒ | âœ… |
| Anomaly detection | âŒ | âŒ | âŒ | âœ… |
| Recommendations | âŒ | âŒ | âŒ | âœ… |
| Risk scoring | âŒ | âŒ | âŒ | âœ… |

### Asset Count Summary

| Asset Type | Count | Coverage |
|------------|:-----:|----------|
| **TVFs** | 60 | All domains |
| **Metric Views** | 10 | Dashboard KPIs |
| **Custom Metrics** | 87 | Time series + alerting |
| **ML Models** | 25 | Predictions + recommendations |
| **Total Semantic Assets** | 182 | â€” |
| **Total Measurements** | 277 | Across all methods |

---

**Version:** 1.1  
**Last Updated:** January 2026  
**Total Measurements:** 277  
**ML Models Integrated:** 25

