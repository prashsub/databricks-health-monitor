[project]
name = "databricks-health-monitor"
version = "1.0.0"
description = "Databricks Health Monitor - Platform Observability Solution"
authors = [
    {name = "Data Engineering Team", email = "data-engineering@company.com"}
]
requires-python = ">=3.10"
dependencies = [
    "pyspark>=3.5.0",
    "delta-spark>=3.0.0",
    "mlflow>=3.0.0",
    "scikit-learn>=1.3.0",
    "xgboost>=2.0.0",
    "lightgbm>=4.0.0",
    "pandas>=2.0.0",
    "numpy>=1.24.0",
    "pyyaml>=6.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "pytest-mock>=3.12.0",
    "pytest-xdist>=3.5.0",
    "chispa>=0.9.4",  # PySpark testing utilities
    "black>=24.0.0",
    "ruff>=0.1.0",
    "mypy>=1.8.0",
]

[tool.pytest.ini_options]
minversion = "7.0"
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "-v",
    "--tb=short",
    "-ra",
    "--strict-markers",
]
markers = [
    "unit: Unit tests that don't require Spark",
    "integration: Integration tests that require Spark",
    "slow: Slow tests that should be run separately",
    "ml: ML model tests",
    "tvf: Table-Valued Function tests",
    "feature: Feature engineering tests",
]
filterwarnings = [
    "ignore::DeprecationWarning",
    "ignore::PendingDeprecationWarning",
]

[tool.coverage.run]
source = ["src"]
branch = true
omit = [
    "*/tests/*",
    "*/__pycache__/*",
]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
]
show_missing = true

[tool.black]
line-length = 100
target-version = ["py310", "py311"]
include = '\.pyi?$'
exclude = '''
/(
    \.git
    | \.venv
    | build
    | dist
    | __pycache__
)/
'''

[tool.ruff]
line-length = 100
target-version = "py310"
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # pyflakes
    "I",   # isort
    "B",   # flake8-bugbear
    "C4",  # flake8-comprehensions
]
ignore = [
    "E501",  # line too long (handled by black)
]

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
ignore_missing_imports = true

[tool.pyright]
# Configuration for basedpyright/pyright
pythonVersion = "3.10"
typeCheckingMode = "basic"

# Databricks notebooks use packages only available in the runtime environment
# These imports cannot be resolved locally but work correctly when deployed
reportMissingImports = "none"

# dbutils is a Databricks-provided global, not available locally
reportUndefinedVariable = "warning"

# These packages are available in Databricks runtime
extraPaths = []

# Exclude generated files
exclude = [
    "**/__pycache__",
    ".venv",
    "build",
    "dist",
]

[tool.basedpyright]
# Configuration for basedpyright (same as pyright)
pythonVersion = "3.10"
typeCheckingMode = "basic"

# Databricks-specific: Suppress missing import errors for runtime packages
# pyspark, mlflow, sklearn, xgboost, databricks.* are only available on Databricks
reportMissingImports = "none"

# dbutils is a Databricks global variable injected at runtime
reportUndefinedVariable = "warning"

exclude = [
    "**/__pycache__",
    ".venv",
    "build",
    "dist",
]
