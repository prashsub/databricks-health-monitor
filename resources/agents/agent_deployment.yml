# Health Monitor Agent Deployment Configuration
# ==============================================
#
# Databricks Asset Bundle resource definitions for the
# Health Monitor Multi-Agent System.
#
# Components:
# 1. Setup job - Creates Lakebase tables and registers prompts
# 2. Model registration job - Logs agent to Unity Catalog
# 3. Model serving endpoint - Deploys agent for inference
# 4. Evaluation job - Runs agent quality evaluation

resources:
  jobs:
    # =========================================================================
    # Setup Job - One-time infrastructure setup
    # =========================================================================
    agent_setup:
      name: "[${bundle.target}] Agent Framework Setup"
      description: "Initialize Lakebase memory tables and register prompts"

      tasks:
        - task_key: setup_lakebase
          description: "Create Lakebase checkpoint and memory tables"
          notebook_task:
            notebook_path: ../src/agents/notebooks/setup_lakebase.py
            base_parameters:
              catalog: ${var.catalog}
              schema: agents
              lakebase_instance: ${var.lakebase_instance_name}
          job_cluster_key: agent_cluster

        - task_key: register_prompts
          description: "Register all prompts to MLflow"
          depends_on:
            - task_key: setup_lakebase
          notebook_task:
            notebook_path: ../src/agents/notebooks/register_prompts.py
            base_parameters:
              catalog: ${var.catalog}
          job_cluster_key: agent_cluster

      job_clusters:
        - job_cluster_key: agent_cluster
          new_cluster:
            spark_version: 15.4.x-scala2.12
            node_type_id: ${var.node_type_id}
            num_workers: 0
            spark_conf:
              spark.databricks.cluster.profile: singleNode
              spark.master: "local[*, 4]"

      tags:
        domain: agents
        phase: setup

    # =========================================================================
    # Model Registration Job
    # =========================================================================
    agent_registration:
      name: "[${bundle.target}] Agent Model Registration"
      description: "Log Health Monitor agent to MLflow Model Registry"

      tasks:
        - task_key: log_agent
          description: "Log agent model with resources"
          notebook_task:
            notebook_path: ../src/agents/notebooks/log_agent.py
            base_parameters:
              catalog: ${var.catalog}
              schema: agents
              model_name: health_monitor_agent
              llm_endpoint: ${var.llm_endpoint}
              lakebase_instance: ${var.lakebase_instance_name}
          job_cluster_key: agent_cluster

      job_clusters:
        - job_cluster_key: agent_cluster
          new_cluster:
            spark_version: 15.4.x-scala2.12
            node_type_id: ${var.node_type_id}
            num_workers: 0
            spark_conf:
              spark.databricks.cluster.profile: singleNode

      tags:
        domain: agents
        phase: registration

    # =========================================================================
    # Evaluation Job
    # =========================================================================
    agent_evaluation:
      name: "[${bundle.target}] Agent Evaluation Pipeline"
      description: "Run evaluation with LLM judges"

      schedule:
        quartz_cron_expression: "0 0 6 * * ?"  # Daily at 6 AM
        timezone_id: "America/Los_Angeles"
        pause_status: PAUSED  # Enable after deployment

      tasks:
        - task_key: run_evaluation
          description: "Evaluate agent with test queries"
          notebook_task:
            notebook_path: ../src/agents/notebooks/run_evaluation.py
            base_parameters:
              catalog: ${var.catalog}
              model_name: health_monitor_agent
          job_cluster_key: agent_cluster

      job_clusters:
        - job_cluster_key: agent_cluster
          new_cluster:
            spark_version: 15.4.x-scala2.12
            node_type_id: ${var.node_type_id}
            num_workers: 0
            spark_conf:
              spark.databricks.cluster.profile: singleNode

      tags:
        domain: agents
        phase: evaluation

  # ===========================================================================
  # Model Serving Endpoint
  # ===========================================================================
  # NOTE: Model serving endpoints should be created via API or CLI
  # after the model is registered. Example configuration below.
  #
  # serving_endpoints:
  #   health_monitor_agent:
  #     name: health_monitor_orchestrator
  #     config:
  #       served_entities:
  #         - entity_name: ${var.catalog}.agents.health_monitor_agent
  #           entity_version: 1
  #           workload_size: Small
  #           scale_to_zero_enabled: true
  #       traffic_config:
  #         routes:
  #           - served_entity_name: ${var.catalog}.agents.health_monitor_agent
  #             traffic_percentage: 100
