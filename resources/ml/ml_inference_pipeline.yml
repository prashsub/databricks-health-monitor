# ML Inference Pipeline - All Models
# Runs batch inference for ALL trained ML models and stores predictions
#
# Storage Architecture:
#   - Feature Tables: ${catalog}.${feature_schema} (e.g., system_gold_ml)
#   - Predictions: ${catalog}.${feature_schema}.{model}_predictions
#   - Models: Unity Catalog ${catalog}.${feature_schema}.{model_name}
#
# Models Scored:
#   - Task 1 (fe.score_batch): 23 models using Feature Store automatic lookup
#     - Cost (5): anomaly, budget, job_cost, chargeback, commitment
#     - Security (4): threat, exfiltration, privilege, user_behavior
#     - Performance (7): query, warehouse, regression, cluster_capacity, dbr_risk, cache_hit, query_optimization
#     - Reliability (5): failure, duration, sla_breach, retry_success, pipeline_health
#     - Quality (2): drift, freshness
#
#   - Task 2 (custom): tag_recommender - uses TF-IDF (runtime feature extraction)
#
# Reference: https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-inference/

resources:
  jobs:
    ml_inference_pipeline:
      name: "[${bundle.target}] Health Monitor - ML Batch Inference (All Models)"
      description: "Runs batch inference for 24 ML models: 23 via Feature Store + 1 custom (tag_recommender)"
      
      # Serverless environment with ML dependencies
      environments:
        - environment_key: ml_inference
          spec:
            environment_version: "4"
            dependencies:
              - "mlflow==3.7.0"        # Pin version to match training environment
              - "scikit-learn>=1.3.0"
              - "pandas>=2.0.0"
              - "numpy>=1.24.0"
              - "xgboost>=2.0.0"       # Required for XGBoost models
              - "databricks-feature-engineering"
      
      tasks:
        # ========================================
        # Task 1: Feature Store Models (23 models)
        # ========================================
        # These models use fe.score_batch() for automatic feature lookup
        - task_key: batch_inference_all_models
          environment_key: ml_inference
          notebook_task:
            notebook_path: ../../src/ml/inference/batch_inference_all_models.py
            base_parameters:
              catalog: ${var.catalog}
              gold_schema: ${var.gold_schema}
              feature_schema: ${var.feature_schema}
          timeout_seconds: 3600  # 1 hour max
        
        # ========================================
        # Task 2: Tag Recommender (Custom Inference)
        # ========================================
        # This model uses TF-IDF features computed at runtime from job names
        # Cannot use fe.score_batch() - requires custom inference pipeline
        - task_key: score_tag_recommender
          depends_on:
            - task_key: batch_inference_all_models
          environment_key: ml_inference
          notebook_task:
            notebook_path: ../../src/ml/inference/score_tag_recommender.py
            base_parameters:
              catalog: ${var.catalog}
              gold_schema: ${var.gold_schema}
              feature_schema: ${var.feature_schema}
          timeout_seconds: 1800  # 30 min max
      
      # Schedule: Daily at 3 AM (after training pipeline completes)
      schedule:
        quartz_cron_expression: "0 0 3 * * ?"
        timezone_id: "America/Los_Angeles"
        pause_status: PAUSED
      
      # Email notifications
      email_notifications:
        on_failure:
          - data-engineering@company.com
        on_success:
          - data-engineering@company.com
      
      tags:
        environment: ${bundle.target}
        project: health_monitor
        layer: ml
        job_type: inference
        compute_type: serverless
        models_count: "24"
        fe_models: "23"
        custom_models: "1"
