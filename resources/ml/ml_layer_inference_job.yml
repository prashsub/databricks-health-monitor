# ML Layer Inference Job (Composite)
# ===================================
# 
# Layer 2 job that orchestrates ML inference.
# References atomic jobs - no notebooks directly.
#
# Execution Flow:
#   1. ML Batch Inference (runs all trained models for prediction)
#
# Pattern: run_job_task references atomic jobs
#
# Usage:
#   databricks bundle run -t dev ml_layer_inference_job
#
# Dependencies: ML models must be trained (run ml_layer_setup_job first)

resources:
  jobs:
    ml_layer_inference_job:
      name: "[${bundle.target}] Health Monitor - ML Layer Inference"
      description: "Composite job: Runs batch inference for all ML models by referencing atomic jobs"
      
      tasks:
        # ================================================================
        # STEP 1: Run Batch Inference for All Models
        # ================================================================
        - task_key: run_batch_inference
          run_job_task:
            job_id: ${resources.jobs.ml_inference_pipeline.id}
      
      # Job-level timeout (2 hours)
      timeout_seconds: 7200
      
      # Email notifications
      email_notifications:
        on_failure:
          - data-engineering@company.com
      
      # Tags
      tags:
        environment: ${bundle.target}
        project: databricks_health_monitor
        layer: ml
        job_type: inference
        job_level: composite
        compute_type: serverless

