---
description: Comprehensive guide for Databricks Lakehouse Monitoring - setup, custom metrics, querying, and best practices
globs: **/*monitoring*.py
alwaysApply: false
---

# Lakehouse Monitoring: Complete Guide for Gold Layer

## ðŸ“‹ Table of Contents

1. [Core Principles](#core-principles)
2. [Setup & Configuration](#setup--configuration)
3. [Custom Metrics Design](#custom-metrics-design)
4. [Querying Metrics](#querying-metrics)
5. [Complete Examples](#complete-examples)
6. [Troubleshooting](#troubleshooting)
7. [AI/BI Dashboard Creation](#aibi-dashboard-creation-from-custom-metrics)
8. [References](#references)

---

## Core Principles

### Principle 1: Graceful Degradation
Monitor setup should handle SDK version differences, missing tables, and existing monitors gracefully.

### Principle 2: Business-First Metrics
Every custom metric must answer: **"What business decision would change based on this metric?"**

### Principle 3: Table-Level Business KPIs
**âš ï¸ CRITICAL:** For table-level business KPIs that reference each other, ALWAYS use `input_columns=[":table"]` for ALL metric types (AGGREGATE, DERIVED, DRIFT).

**Why This Matters:**
- DERIVED metrics can ONLY reference metrics in the same `column_name` row
- DRIFT metrics can ONLY compare metrics in the same `column_name` row  
- Mixing `input_columns` values breaks cross-references â†’ NULL values

**Decision Tree:**
```
Is this a table-level business KPI?
â”œâ”€ YES â†’ Use input_columns=[":table"]
â”‚        - Will be used in DERIVED metrics
â”‚        - Will be compared in DRIFT metrics
â”‚        - Represents overall business state
â”‚        â†’ ALL RELATED METRICS MUST USE [":table"]
â”‚
â””â”€ NO â†’ Is it column-specific profiling?
         â””â”€ YES â†’ Use input_columns=["column_name"]
                  - Tracks column-specific statistics
                  - Won't be referenced by other metrics
                  - Pure data quality monitoring
```

### Principle 4: Where Custom Metrics Appear

**âš ï¸ CRITICAL:** Custom metrics appear as **NEW COLUMNS** in monitoring output tables:
- **AGGREGATE + DERIVED metrics** â†’ `{table}_profile_metrics` table (as new columns)
- **DRIFT metrics** â†’ `{table}_drift_metrics` table (as new columns)
- **There is NO separate `custom_metrics` table!**

---

## Setup & Configuration

### Import with Graceful Fallback

```python
# âœ… CORRECT: Try-except for optional monitoring classes
try:
    from databricks.sdk.service.catalog import (
        MonitorTimeSeries, 
        MonitorSnapshot, 
        MonitorMetric, 
        MonitorMetricType, 
        MonitorCronSchedule
    )
    MONITORING_AVAILABLE = True
except ImportError:
    MONITORING_AVAILABLE = False
    print("âš ï¸  Lakehouse Monitoring classes not available in this SDK version")

# Check before use
if not MONITORING_AVAILABLE:
    print("âš ï¸  Skipping monitoring setup - SDK version incompatible")
    return
```

### Exception Handling

```python
from databricks.sdk.errors import ResourceAlreadyExists, ResourceDoesNotExist

try:
    monitor = workspace_client.quality_monitors.create(
        table_name=f"{catalog}.{schema}.{table}",
        # ... configuration
    )
    print(f"âœ“ Monitor created for {table}")
except ResourceAlreadyExists:
    print(f"âš ï¸  Monitor for {table} already exists - skipping")
except ResourceDoesNotExist:
    print(f"âš ï¸  Table {table} does not exist - skipping monitor creation")
except Exception as e:
    print(f"âš ï¸  Failed to create monitor for {table}: {e}")
```

### Monitor Mode Configuration

**Critical Rule: Always Specify ONE of: `snapshot`, `time_series`, or `inference_log`**

```python
# âŒ WRONG: No mode specified
monitor = workspace_client.quality_monitors.create(
    table_name=table_name,
    # âŒ ERROR: Must specify snapshot, time_series, or inference_log
)

# âœ… CORRECT: Snapshot mode
monitor = workspace_client.quality_monitors.create(
    table_name=table_name,
    snapshot=MonitorSnapshot(),  # âœ… For non-temporal data
    custom_metrics=[...],
)

# âœ… CORRECT: Time series mode
monitor = workspace_client.quality_monitors.create(
    table_name=table_name,
    time_series=MonitorTimeSeries(
        timestamp_col="transaction_date",
        granularities=["1 day"]
    ),
    custom_metrics=[...],
)
```

**When to Use Each Mode:**

| Mode | Use Case | Example |
|------|----------|---------|
| `snapshot` | Daily snapshots without time dimension | `fact_inventory_snapshot` |
| `time_series` | Temporal data with timestamp column | `fact_sales_daily` |
| `inference_log` | ML model inference monitoring | Model prediction tables |

### Complete Monitor Creation Template

```python
def create_table_monitor(
    workspace_client: WorkspaceClient, 
    catalog: str, 
    schema: str,
    table: str,
    monitor_type: str = "time_series"
):
    """
    Create Lakehouse monitor with comprehensive error handling.
    
    Args:
        monitor_type: "snapshot" or "time_series"
    """
    table_name = f"{catalog}.{schema}.{table}"
    
    print(f"Creating {monitor_type} monitor for {table_name}...")
    
    try:
        # Configure monitor based on type
        if monitor_type == "snapshot":
            config = {"snapshot": MonitorSnapshot()}
        elif monitor_type == "time_series":
            config = {
                "time_series": MonitorTimeSeries(
                    timestamp_col="transaction_date",
                    granularities=["1 day"]
                )
            }
        
        monitor = workspace_client.quality_monitors.create(
            table_name=table_name,
            assets_dir=f"/Workspace/Shared/lakehouse_monitoring/{catalog}/{schema}",
            output_schema_name=f"{catalog}.{schema}_monitoring",
            **config,
            custom_metrics=[
                # See Custom Metrics Design section below
            ],
            slicing_exprs=["store_number", "upc_code"],  # Dimensional analysis
            schedule=MonitorCronSchedule(
                quartz_cron_expression="0 0 2 * * ?",  # Daily at 2 AM
                timezone_id="America/New_York"
            )
        )
        
        print(f"âœ“ Monitor created for {table_name}")
        if hasattr(monitor, 'table_name'):
            print(f"  Table: {monitor.table_name}")
        if hasattr(monitor, 'dashboard_id'):
            print(f"  Dashboard: {monitor.dashboard_id}")
        
        return monitor
        
    except ResourceAlreadyExists:
        print(f"âš ï¸  Monitor for {table} already exists - skipping")
        return None
        
    except ResourceDoesNotExist:
        print(f"âš ï¸  Table {table} does not exist - skipping monitor creation")
        return None
        
    except Exception as e:
        print(f"âŒ Failed to create monitor for {table}: {str(e)}")
        raise
```

### Async Operations Pattern

**Critical Rule: Wait for Table Creation**

Lakehouse Monitoring creates output tables asynchronously:
1. Monitor API call returns immediately (~30 seconds)
2. Initial profiling runs in background (~15 minutes)
3. Tables don't exist until profiling completes

```python
def wait_with_progress(minutes: int = 15):
    """Wait with progress updates."""
    wait_seconds = minutes * 60
    for elapsed in range(0, wait_seconds, 60):
        progress_pct = (elapsed / wait_seconds) * 100
        remaining = wait_seconds - elapsed
        print(f"â±ï¸  Progress: {progress_pct:.1f}% | Remaining: {remaining//60}m")
        time.sleep(60)
    print(f"âœ“ Wait completed - tables should be ready")

# Use in workflow
create_sales_monitor(workspace_client, catalog, schema)
wait_with_progress(minutes=15)  # âœ… Wait for async table creation
document_monitoring_tables(spark, catalog, schema)  # âœ… Now tables exist
```

### Complete Monitor Cleanup Pattern

**Critical Rule: Delete Monitor AND Output Tables**

Problem: Deleting a monitor doesn't delete its output tables, causing schema conflicts.

```python
def delete_monitor_if_exists(workspace_client: WorkspaceClient, table_name: str, spark=None):
    """Complete cleanup: monitor definition + output tables."""
    from pyspark.sql import SparkSession
    
    if spark is None:
        spark = SparkSession.getActiveSession()
    
    try:
        # 1. Check if monitor exists
        workspace_client.quality_monitors.get(table_name=table_name)
        
        # 2. Delete monitor definition
        print(f"  Deleting existing monitor for {table_name}...")
        workspace_client.quality_monitors.delete(table_name=table_name)
        print(f"  âœ“ Existing monitor deleted")
        
        # 3. Parse table name to construct monitoring table names
        catalog, schema, table = table_name.split(".")
        monitoring_schema = f"{schema}_monitoring"
        
        # 4. Drop profile_metrics table
        profile_table = f"{catalog}.{monitoring_schema}.{table}_profile_metrics"
        print(f"  Dropping profile metrics table: {profile_table}...")
        spark.sql(f"DROP TABLE IF EXISTS {profile_table}")
        print(f"  âœ“ Profile metrics table dropped")
        
        # 5. Drop drift_metrics table
        drift_table = f"{catalog}.{monitoring_schema}.{table}_drift_metrics"
        print(f"  Dropping drift metrics table: {drift_table}...")
        spark.sql(f"DROP TABLE IF EXISTS {drift_table}")
        print(f"  âœ“ Drift metrics table dropped")
        
        return True
        
    except ResourceDoesNotExist:
        return False  # Silent success - nothing to delete
    except Exception as e:
        print(f"  âš ï¸  Error checking/deleting monitor: {str(e)}")
        return False

# Use before creating new monitor
delete_monitor_if_exists(workspace_client, sales_table, spark)
create_sales_monitor(workspace_client, catalog, schema)
```

### Monitor Update Pattern

**âš ï¸ CRITICAL:** `quality_monitors.update()` is a **REPLACEMENT operation, not a MERGE**. If you omit fields (especially `custom_metrics`), they are **DELETED**.

**âœ… CORRECT: Import from Pure Python Configuration File**

```python
# monitor_configs.py (pure Python file - NOT a notebook)
"""Centralized Monitor Configuration for Lakehouse Monitoring"""

from databricks.sdk.service.catalog import (
    MonitorTimeSeries, MonitorSnapshot, MonitorMetric, 
    MonitorMetricType, MonitorCronSchedule
)
import pyspark.sql.types as T

def get_all_monitor_configs(catalog: str, schema: str):
    """Get all monitor configurations with FULL custom metrics"""
    return [
        {
            "table_name": f"{catalog}.{schema}.fact_sales_daily",
            "custom_metrics": [... 99 metrics ...],  # âœ… MUST include all metrics
            "slicing_exprs": ["store_number"],
        }
    ]
```

```python
# update_monitors.py (notebook)
from monitor_configs import get_all_monitor_configs
from databricks.sdk import WorkspaceClient

def main():
    catalog, schema = get_parameters()
    workspace_client = WorkspaceClient()
    
    # âœ… Get FULL configuration including all custom metrics
    monitor_configs = get_all_monitor_configs(catalog, schema)
    
    # Verify custom metrics are included
    for config in monitor_configs:
        custom_metrics = config.get('custom_metrics', [])
        print(f"Updating with {len(custom_metrics)} custom metrics")
    
    # Update with full configuration
    for config in monitor_configs:
        workspace_client.quality_monitors.update(**config)
```

**Update Behavior:**

| What You Pass | What Happens |
|---------------|--------------|
| `custom_metrics=None` | âŒ Deletes all custom metrics |
| `custom_metrics=[]` | âŒ Deletes all custom metrics |
| Omit `custom_metrics` | âŒ Deletes all custom metrics |
| `custom_metrics=[...]` | âœ… Replaces with provided list |

---

## Custom Metrics Design

### Business-Focused Metric Categories

#### 1. Transaction Pattern Metrics

**Purpose:** Track customer purchasing behavior changes

```python
# Average spend per transaction
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
    name="avg_transaction_amount",
    input_columns=[":table"],  # âœ… Table-level business KPI
    definition="AVG(avg_transaction_value)",
    output_data_type=T.StructField("output", T.DoubleType()).json()
)

# Items per basket (DERIVED - references AGGREGATE metrics)
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_DERIVED,
    name="avg_items_per_transaction",
    input_columns=[":table"],  # âœ… Must match AGGREGATE
    definition="total_net_units / NULLIF(total_transactions, 0)",
    output_data_type=T.StructField("output", T.DoubleType()).json()
)

# Store traffic
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
    name="transactions_per_store_per_day",
    input_columns=[":table"],  # âœ… Table-level business KPI
    definition="AVG(transaction_count)",
    output_data_type=T.StructField("output", T.DoubleType()).json()
)
```

**Business Questions Answered:**
- Is average basket size declining?
- Are customers buying fewer items?
- Is store traffic decreasing?

#### 2. Product Performance Metrics

**Purpose:** Monitor product sales velocity and availability

```python
# Product sales velocity
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
    name="product_velocity",
    input_columns=[":table"],  # âœ… Table-level business KPI
    definition="SUM(net_units) / NULLIF(COUNT(DISTINCT store_number), 0)",
    output_data_type=T.StructField("output", T.DoubleType()).json()
)

# Dollar productivity per SKU
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
    name="revenue_per_product",
    input_columns=[":table"],  # âœ… Table-level business KPI
    definition="AVG(net_revenue)",
    output_data_type=T.StructField("output", T.DoubleType()).json()
)

# In-stock percentage
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
    name="product_availability_rate",
    input_columns=[":table"],  # âœ… Table-level business KPI
    definition="(COUNT(CASE WHEN net_units > 0 THEN 1 END) / NULLIF(COUNT(*), 0)) * 100",
    output_data_type=T.StructField("output", T.DoubleType()).json()
)
```

#### 3. Customer Segmentation Metrics

**Purpose:** Track loyalty program and customer behavior

```python
# Loyalty member value (DERIVED - references AGGREGATE)
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_DERIVED,
    name="loyalty_member_avg_spend",
    input_columns=[":table"],  # âœ… Must match AGGREGATE
    definition="total_net_revenue / NULLIF(total_loyalty_customers, 0)",
    output_data_type=T.StructField("output", T.DoubleType()).json()
)

# Member visit frequency (DERIVED - references AGGREGATE)
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_DERIVED,
    name="loyalty_transaction_frequency",
    input_columns=[":table"],  # âœ… Must match AGGREGATE
    definition="total_loyalty_transactions / NULLIF(total_loyalty_customers, 0)",
    output_data_type=T.StructField("output", T.DoubleType()).json()
)
```

#### 4. Promotional Effectiveness Metrics

**Purpose:** Track discount strategy and campaign ROI

```python
# Discount intensity (DERIVED - references AGGREGATE)
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_DERIVED,
    name="discount_intensity",
    input_columns=[":table"],  # âœ… Must match AGGREGATE
    definition="(total_all_discounts / NULLIF(total_gross_revenue, 0)) * 100",
    output_data_type=T.StructField("output", T.DoubleType()).json()
)

# Campaign effectiveness
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
    name="coupon_redemption_rate",
    input_columns=[":table"],  # âœ… Table-level business KPI
    definition="(COUNT(CASE WHEN coupon_discount_total > 0 THEN 1 END) / NULLIF(COUNT(*), 0)) * 100",
    output_data_type=T.StructField("output", T.DoubleType()).json()
)
```

#### 5. Drift Metrics (Period-over-Period Comparison)

**Purpose:** Automatic anomaly detection for business KPIs

```python
# Revenue drift percentage
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_DRIFT,
    name="revenue_drift_pct",
    input_columns=[":table"],  # âœ… Must match AGGREGATE
    definition="(({{current_df}}.total_net_revenue - {{base_df}}.total_net_revenue) / NULLIF({{base_df}}.total_net_revenue, 0)) * 100",
    output_data_type=T.StructField("output", T.DoubleType()).json()
)

# Transaction volume drift
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_DRIFT,
    name="transaction_drift_pct",
    input_columns=[":table"],  # âœ… Must match AGGREGATE
    definition="(({{current_df}}.total_transactions - {{base_df}}.total_transactions) / NULLIF({{base_df}}.total_transactions, 0)) * 100",
    output_data_type=T.StructField("output", T.DoubleType()).json()
)
```

### Custom Metric Limitations

**Critical Rule: No Nested Aggregations**

Databricks does NOT support aggregate functions inside other aggregate functions.

```python
# âŒ WRONG: Nested aggregation
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
    name="top_10_stores_revenue_share",
    definition="(SUM(CASE WHEN net_revenue >= PERCENTILE(net_revenue, 0.9) THEN net_revenue ELSE 0 END) / NULLIF(SUM(net_revenue), 0)) * 100"
    # âŒ ERROR: PERCENTILE inside SUM
)

# âœ… CORRECT: Two-step pattern (AGGREGATE â†’ DERIVED)
# Step 1: Define base aggregates
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
    name="total_revenue",
    input_columns=[":table"],
    definition="SUM(revenue)"
),
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
    name="p90_revenue",
    input_columns=[":table"],
    definition="PERCENTILE(revenue, 0.9)"
),

# Step 2: Define derived ratio
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_DERIVED,
    name="top_performer_share",
    input_columns=[":table"],
    definition="p90_revenue / NULLIF(total_revenue, 0) * 100"  # âœ… References aggregates
)
```

### Metric Organization Pattern

**Group metrics by business domain with clear comments:**

```python
custom_metrics=[
    # ========================================
    # TRANSACTION PATTERN METRICS
    # ========================================
    # Purpose: Track customer purchasing behavior changes
    
    MonitorMetric(...),  # avg_transaction_amount
    MonitorMetric(...),  # avg_items_per_transaction
    MonitorMetric(...),  # transactions_per_store_per_day
    
    # ========================================
    # PRODUCT PERFORMANCE METRICS
    # ========================================
    # Purpose: Monitor product sales velocity and availability
    
    MonitorMetric(...),  # product_velocity
    MonitorMetric(...),  # revenue_per_product
    MonitorMetric(...),  # product_availability_rate
    
    # ... more categories
]
```

### Documenting Custom Metrics

**Critical: Document metrics in the correct tables**

Custom metrics appear as NEW COLUMNS in monitoring output tables:
- AGGREGATE + DERIVED metrics â†’ `{table}_profile_metrics` table
- DRIFT metrics â†’ `{table}_drift_metrics` table
- **There is NO separate `custom_metrics` table!**

```python
def document_profile_metrics_table(spark: SparkSession, catalog: str, schema: str, table: str):
    """
    Document profile_metrics table including custom metric columns.
    
    âš ï¸ KEY INSIGHT: Custom aggregate/derived metrics appear as NEW COLUMNS here.
    """
    monitoring_schema = f"{schema}_monitoring"
    profile_table = f"{catalog}.{monitoring_schema}.{table}_profile_metrics"
    
    if table == "fact_sales_daily":
        custom_metrics_descriptions = {
            # Use dual-purpose format: Business + Technical
            "avg_transaction_amount": """Average transaction basket size. 
                Business: Tracks how customer spending per visit changes over time. 
                Decline signals reduced basket size. 
                Technical: AVG(avg_transaction_value), key drift indicator.""",
            
            "product_velocity": """Average units sold per store. 
                Business: Measures product movement speed changes. 
                Technical: SUM(net_units) / COUNT(DISTINCT stores).""",
            
            # ... more metrics
        }
        
        for column_name, description in custom_metrics_descriptions.items():
            try:
                spark.sql(f"ALTER TABLE {profile_table} ALTER COLUMN {column_name} COMMENT '{description}'")
            except:
                pass  # Column may not exist yet
```

---

## Querying Metrics

### Storage Pattern by Metric Type

**Critical Rule:** The `input_columns` parameter determines WHERE metrics are stored.

| input_columns Value | Stored Where |
|---------------------|--------------|
| `["column_name"]` | `column_name = 'column_name'` row |
| `[":table"]` | `column_name = ':table'` row |
| `["col1", "col2"]` | `column_name = ':table'` (multi-column) |

### Query Pattern 1: Table-Level AGGREGATE (Direct SELECT)

**Recommended for business KPIs**

```sql
-- Python: input_columns=[":table"]

SELECT 
  window.start,
  window.end,
  -- All table-level metrics available directly
  total_gross_revenue,
  total_net_revenue,
  total_transactions,
  avg_transaction_amount
FROM fact_sales_daily_profile_metrics
WHERE log_type = 'INPUT'
  AND column_name = ':table'  -- âœ… All table-level metrics here
  AND COALESCE(slice_key, 'No Slice') = :slice_key
ORDER BY window.start DESC
```

### Query Pattern 2: DERIVED Metrics (Direct SELECT)

```sql
-- Python: input_columns=[":table"]

SELECT 
  window.start,
  window.end,
  overall_return_rate,
  units_per_transaction,
  revenue_per_unit,
  discount_intensity
FROM fact_sales_daily_profile_metrics
WHERE log_type = 'INPUT'
  AND column_name = ':table'  -- All DERIVED metrics here
  AND COALESCE(slice_key, 'No Slice') = :slice_key
```

### Query Pattern 3: DRIFT Metrics (Separate Table)

```sql
-- Python: input_columns=[":table"]

SELECT 
  window.start,
  drift_type,
  revenue_drift_pct,
  transaction_drift_pct,
  unit_sales_drift_pct
FROM fact_sales_daily_drift_metrics
WHERE drift_type = 'CONSECUTIVE'  -- or 'BASELINE'
  AND column_name = ':table'
  AND COALESCE(slice_key, 'No Slice') = :slice_key
ORDER BY window.start DESC
```

### Query Pattern 4: Per-Column AGGREGATE (PIVOT Required)

**âš ï¸ Only for column-specific profiling (rare use case)**

```sql
-- Python: input_columns=["gross_revenue"]

WITH base_metrics AS (
  SELECT 
    window, granularity, slice_key, slice_value,
    column_name,
    gross_revenue_outlier_count,  -- Custom metric column
    net_revenue_outlier_count
  FROM fact_sales_daily_profile_metrics
  WHERE log_type = 'INPUT'
    AND column_name IN ('gross_revenue', 'net_revenue')  -- Input columns
)
SELECT 
  window.start,
  window.end,
  MAX(CASE WHEN column_name = 'gross_revenue' THEN gross_revenue_outlier_count END) AS gross_revenue_outliers,
  MAX(CASE WHEN column_name = 'net_revenue' THEN net_revenue_outlier_count END) AS net_revenue_outliers
FROM base_metrics
GROUP BY window.start, window.end, granularity, slice_key, slice_value
```

### AI/BI Dashboard Dataset Patterns

**Dataset Type 1: Table-Level Business KPIs (Direct SELECT)**

```sql
-- No PIVOT needed for table-level metrics!
SELECT 
  window.start AS date,
  window.end,
  COALESCE(slice_key, 'No Slice') AS slice_key_display,
  COALESCE(slice_value, 'No Slice') AS slice_value_display,
  total_net_revenue,
  total_transactions,
  avg_transaction_amount,
  overall_return_rate,
  discount_intensity
FROM fact_sales_daily_profile_metrics
WHERE log_type = 'INPUT'
  AND column_name = ':table'  -- âœ… All table-level metrics in one row
  AND slice_key_display = :slice_key
  AND slice_value_display = :slice_value
ORDER BY date DESC
```

**Dataset Type 2: Slice Filters (Cascading)**

```sql
-- Slice Key Filter
SELECT 'No Slice' AS `Slice Key`
UNION ALL
SELECT DISTINCT slice_key AS `Slice Key`
FROM fact_sales_daily_profile_metrics
WHERE slice_key IS NOT NULL
ORDER BY `Slice Key`

-- Slice Value Filter (depends on Slice Key)
SELECT 'No Slice' AS `Slice Value`
UNION ALL
SELECT DISTINCT slice_value AS `Slice Value`
FROM fact_sales_daily_profile_metrics
WHERE COALESCE(slice_key, 'No Slice') = :slice_key
  AND slice_value IS NOT NULL
ORDER BY `Slice Value`
```

---

## Complete Examples

### Example 1: Sales Monitor with Comprehensive Metrics

```python
def create_sales_monitor(workspace_client: WorkspaceClient, catalog: str, schema: str):
    """Create fact_sales_daily monitor with business-focused metrics."""
    
    table_name = f"{catalog}.{schema}.fact_sales_daily"
    
    # Delete existing monitor + tables
    delete_monitor_if_exists(workspace_client, table_name, spark)
    
    # Create new monitor
    monitor = workspace_client.quality_monitors.create(
        table_name=table_name,
        assets_dir=f"/Workspace/Shared/lakehouse_monitoring/{catalog}/{schema}",
        output_schema_name=f"{catalog}.{schema}_monitoring",
        time_series=MonitorTimeSeries(
            timestamp_col="transaction_date",
            granularities=["1 day"]
        ),
        custom_metrics=[
            # ========================================
            # AGGREGATE METRICS (Base Measurements)
            # ========================================
            MonitorMetric(
                type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
                name="total_gross_revenue",
                input_columns=[":table"],  # âœ… Table-level
                definition="SUM(gross_revenue)",
                output_data_type=T.StructField("output", T.DoubleType()).json()
            ),
            MonitorMetric(
                type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
                name="total_net_revenue",
                input_columns=[":table"],  # âœ… Table-level
                definition="SUM(net_revenue)",
                output_data_type=T.StructField("output", T.DoubleType()).json()
            ),
            MonitorMetric(
                type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
                name="total_transactions",
                input_columns=[":table"],  # âœ… Table-level
                definition="SUM(transaction_count)",
                output_data_type=T.StructField("output", T.LongType()).json()
            ),
            
            # ========================================
            # DERIVED METRICS (Business Ratios)
            # ========================================
            MonitorMetric(
                type=MonitorMetricType.CUSTOM_METRIC_TYPE_DERIVED,
                name="overall_return_rate",
                input_columns=[":table"],  # âœ… Must match AGGREGATE
                definition="(total_return_amount / NULLIF(total_gross_revenue, 0)) * 100",
                output_data_type=T.StructField("output", T.DoubleType()).json()
            ),
            MonitorMetric(
                type=MonitorMetricType.CUSTOM_METRIC_TYPE_DERIVED,
                name="avg_items_per_transaction",
                input_columns=[":table"],  # âœ… Must match AGGREGATE
                definition="total_net_units / NULLIF(total_transactions, 0)",
                output_data_type=T.StructField("output", T.DoubleType()).json()
            ),
            
            # ========================================
            # DRIFT METRICS (Period Comparison)
            # ========================================
            MonitorMetric(
                type=MonitorMetricType.CUSTOM_METRIC_TYPE_DRIFT,
                name="revenue_drift_pct",
                input_columns=[":table"],  # âœ… Must match AGGREGATE
                definition="(({{current_df}}.total_net_revenue - {{base_df}}.total_net_revenue) / NULLIF({{base_df}}.total_net_revenue, 0)) * 100",
                output_data_type=T.StructField("output", T.DoubleType()).json()
            ),
        ],
        slicing_exprs=["store_number", "upc_code"],
        schedule=MonitorCronSchedule(
            quartz_cron_expression="0 0 2 * * ?",
            timezone_id="America/New_York"
        )
    )
    
    return monitor
```

### Example 2: Complete Workflow

```python
def main():
    """Setup Lakehouse monitoring with graceful error handling."""
    
    # Check SDK compatibility
    if not MONITORING_AVAILABLE:
        print("âš ï¸  Skipping monitoring - incompatible SDK version")
        return
    
    catalog, schema = get_parameters()
    spark = SparkSession.getActiveSession()
    workspace_client = WorkspaceClient()
    
    # Tables to monitor with their types
    monitoring_config = [
        ("fact_sales_daily", "time_series"),
        ("fact_inventory_snapshot", "snapshot"),
    ]
    
    monitors_created = []
    
    for table, monitor_type in monitoring_config:
        try:
            monitor = create_table_monitor(
                workspace_client, 
                catalog, 
                schema, 
                table,
                monitor_type
            )
            if monitor:
                monitors_created.append(table)
        except Exception as e:
            print(f"âš ï¸  Continuing after error with {table}: {e}")
            continue
    
    print("\n" + "=" * 80)
    print("âœ“ Lakehouse Monitoring setup completed")
    print("=" * 80)
    print(f"\nMonitors successfully created: {len(monitors_created)}")
    for table in monitors_created:
        print(f"  â€¢ {table}")
    
    # Wait for tables to be created
    if monitors_created:
        print("\nâ±ï¸  Waiting 15 minutes for monitor initialization...")
        wait_with_progress(minutes=15)
        
        # Document monitoring tables
        print("\nðŸ“ Documenting monitoring tables...")
        for table in monitors_created:
            document_monitoring_tables(spark, catalog, schema, table)
        
        print("\nâœ… Monitoring setup complete with documentation!")
```

---

## Troubleshooting

### Common Mistakes

#### âŒ Mistake 1: Mixing `input_columns` Values

**THE MOST COMMON ERROR**

```python
# âŒ WRONG: AGGREGATE and DERIVED use different input_columns
MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_AGGREGATE,
    name="total_gross_revenue",
    input_columns=["gross_revenue"],  # â† Stored in 'gross_revenue' row
    definition="SUM(gross_revenue)"
)

MonitorMetric(
    type=MonitorMetricType.CUSTOM_METRIC_TYPE_DERIVED,
    name="overall_return_rate",
    input_columns=[":table"],  # â† Looks in ':table' row
    definition="(total_return_amount / NULLIF(total_gross_revenue, 0)) * 100"
    # âŒ Can't find total_gross_revenue!
)

# Result: overall_return_rate is NULL
```

```python
# âœ… CORRECT: All use same input_columns
MonitorMetric(
    name="total_gross_revenue",
    input_columns=[":table"],  # âœ… Table-level
    definition="SUM(gross_revenue)"
)

MonitorMetric(
    name="overall_return_rate",
    input_columns=[":table"],  # âœ… Same location
    definition="(total_return_amount / NULLIF(total_gross_revenue, 0)) * 100"
)

# Result: Both calculate correctly
```

#### âŒ Mistake 2: Not Specifying Monitor Mode

```python
# âŒ WRONG: No mode specified
monitor = workspace_client.quality_monitors.create(
    table_name=table_name,
    # Missing: snapshot, time_series, or inference_log
)

# âœ… CORRECT: Explicit mode
monitor = workspace_client.quality_monitors.create(
    table_name=table_name,
    snapshot=MonitorSnapshot(),  # âœ… or time_series
    custom_metrics=[...],
)
```

#### âŒ Mistake 3: Querying Wrong `column_name`

```python
# Python: input_columns=[":table"]

# âŒ WRONG Query:
WHERE column_name IN ('gross_revenue', 'net_revenue')  # Returns NULL!

# âœ… CORRECT Query:
WHERE column_name = ':table'  # Has values!
```

#### âŒ Mistake 4: Updating Without Full Custom Metrics

```python
# âŒ WRONG: Simplified config deletes all metrics
def get_all_monitor_configs(catalog, schema):
    return [
        {
            "table_name": f"{catalog}.{schema}.fact_sales_daily",
            "slicing_exprs": ["store_number"],
            # âŒ Missing custom_metrics â†’ ALL 99 METRICS DELETED!
        }
    ]

# âœ… CORRECT: Always include full custom_metrics
def get_all_monitor_configs(catalog, schema):
    return [
        {
            "table_name": f"{catalog}.{schema}.fact_sales_daily",
            "custom_metrics": [... all 99 metrics ...],  # âœ… Full list
            "slicing_exprs": ["store_number"],
        }
    ]
```

#### âŒ Mistake 5: Trying to Document `custom_metrics` Table

```python
# âŒ WRONG: This table doesn't exist!
custom_table = f"{catalog}.{schema}_monitoring.fact_sales_daily_custom_metrics"
spark.sql(f"ALTER TABLE {custom_table} ALTER COLUMN metric_name COMMENT '...'")
# âŒ ERROR: TABLE_OR_VIEW_NOT_FOUND

# âœ… CORRECT: Document columns in profile_metrics and drift_metrics
profile_table = f"{catalog}.{schema}_monitoring.fact_sales_daily_profile_metrics"
spark.sql(f"ALTER TABLE {profile_table} ALTER COLUMN total_net_revenue COMMENT '...'")
```

### Verification Workflow

**Step 1: Check Python Definition**

```python
# In lakehouse_monitoring.py
MonitorMetric(
    name="total_gross_revenue",
    input_columns=[":table"],  # â† Note this!
    definition="SUM(gross_revenue)"
)
```

**Step 2: Determine Storage Location**

| input_columns | Stored Where |
|---------------|--------------|
| `[":table"]` | `column_name = ':table'` |
| `["gross_revenue"]` | `column_name = 'gross_revenue'` |

**Step 3: Test Query**

```sql
-- Debug: See where metric has values
SELECT column_name, total_gross_revenue
FROM fact_sales_daily_profile_metrics
WHERE total_gross_revenue IS NOT NULL
  AND log_type = 'INPUT'
LIMIT 10;

-- Result shows: column_name = ':table'
```

### Validation Checklist

**Setup & Configuration:**
- [ ] Import monitoring classes with try-except
- [ ] Check MONITORING_AVAILABLE before creating
- [ ] Specify ONE of: snapshot, time_series, inference_log
- [ ] Handle ResourceAlreadyExists and ResourceDoesNotExist
- [ ] Use hasattr() for MonitorInfo attributes
- [ ] Delete existing monitor + tables before recreating

**Custom Metrics:**
- [ ] **CRITICAL:** All table-level business KPIs use `input_columns=[":table"]`
- [ ] All related metrics (AGGREGATE/DERIVED/DRIFT) use same `input_columns`
- [ ] No nested aggregations
- [ ] Use DERIVED metrics for ratios
- [ ] NULLIF guards against division by zero
- [ ] All metrics have output_data_type specified
- [ ] Metrics organized by business category

**Querying:**
- [ ] Use `log_type = 'INPUT'` (not 'OUTPUT')
- [ ] Filter to correct `column_name` value
- [ ] Handle NULL slices with COALESCE
- [ ] Use PIVOT only for per-column metrics (rare)
- [ ] Direct SELECT for table-level metrics (common)

**Documentation:**
- [ ] Document metrics in `profile_metrics` (AGGREGATE + DERIVED)
- [ ] Document metrics in `drift_metrics` (DRIFT type)
- [ ] Use dual-purpose format (Business + Technical)
- [ ] Do NOT try to document `custom_metrics` table (doesn't exist)

**Workflow:**
- [ ] Wait 15+ minutes after creation before querying
- [ ] Update with FULL configuration (never omit custom_metrics)
- [ ] Use silent success pattern for idempotent operations
- [ ] Verify metric counts match before/after updates

---

## AI/BI Dashboard Creation from Custom Metrics

### Dashboard Architecture Patterns

**Critical Rule: Organize datasets by business purpose, not by metric type.**

#### Dataset Organization Strategy

```json
{
  "datasets": [
    // 1. Core Aggregate Metrics (Foundational)
    {
      "name": "sales_aggregate_core",
      "displayName": "Sales Core Aggregate Metrics",
      "queryLines": ["SELECT window.start, window.end,",
                     "  total_gross_revenue, total_net_revenue, ...",
                     "FROM profile_metrics",
                     "WHERE column_name = ':table' ..."]
    },
    
    // 2. Derived KPIs (Business Ratios)
    {
      "name": "sales_derived_kpis",
      "displayName": "Sales Derived KPIs and Ratios",
      "queryLines": ["SELECT window.start, window.end,",
                     "  overall_return_rate, discount_intensity, ...",
                     "FROM profile_metrics",
                     "WHERE column_name = ':table' ..."]
    },
    
    // 3. Data Quality Metrics
    {
      "name": "sales_data_quality",
      "displayName": "Sales Data Quality Metrics",
      "queryLines": ["SELECT window.start, window.end,",
                     "  total_records, null_rate_*, zero_revenue_records, ...",
                     "FROM profile_metrics",
                     "WHERE column_name = ':table' ..."]
    },
    
    // 4. Drift Metrics (Period Comparison)
    {
      "name": "sales_drift_metrics",
      "displayName": "Sales Drift Metrics (Period-over-Period)",
      "queryLines": ["SELECT window.start, drift_type,",
                     "  revenue_drift_pct, transaction_drift_pct, ...",
                     "FROM drift_metrics",
                     "WHERE column_name = ':table' ..."]
    },
    
    // 5-N. Time Series Datasets (Chart-Specific)
    {
      "name": "sales_revenue_trend",
      "displayName": "Sales Revenue Trend (Time Series)",
      "queryLines": ["SELECT window.start,",
                     "  total_gross_revenue, total_net_revenue, total_return_amount",
                     "FROM profile_metrics",
                     "WHERE column_name = ':table' ..."]
    }
  ]
}
```

**Benefits of This Pattern:**
- âœ… Clear separation of concerns
- âœ… Easy to add new metrics to correct category
- âœ… Reusable datasets across multiple widgets
- âœ… Intuitive for dashboard consumers

### Standard Query Patterns for Monitoring Tables

#### Pattern 1: Profile Metrics (AGGREGATE + DERIVED)

```sql
SELECT 
  window.start AS window_start,
  window.end AS window_end,
  -- Custom AGGREGATE metrics
  total_gross_revenue,
  total_net_revenue,
  total_transactions,
  -- Custom DERIVED metrics
  overall_return_rate,
  discount_intensity,
  units_per_transaction
FROM `{catalog}`.`{schema}_monitoring`.`{table}_profile_metrics`
WHERE window.start >= :`Time Window Start`
  AND window.end <= :`Time Window End`
  AND log_type = 'INPUT'                              -- Always INPUT
  AND column_name = ':table'                          -- Table-level metrics
  AND COALESCE(slice_key, 'No Slice') = :slice_key    -- Handle NULL slices
  AND COALESCE(slice_value, 'No Slice') = :slice_value
ORDER BY window.start DESC
```

**Key Elements:**
- `log_type = 'INPUT'` - Always use INPUT (not OUTPUT)
- `column_name = ':table'` - For table-level business KPIs
- `COALESCE(slice_key, 'No Slice')` - Handle NULL slices gracefully
- Time window filtering with parameters

#### Pattern 2: Drift Metrics

```sql
SELECT 
  window.start AS window_start,
  drift_type,
  -- Custom DRIFT metrics
  revenue_drift_pct,
  transaction_volume_drift_pct,
  unit_sales_drift_pct,
  discount_intensity_drift
FROM `{catalog}`.`{schema}_monitoring`.`{table}_drift_metrics`
WHERE window.start >= :`Time Window Start`
  AND window.start <= :`Time Window End`
  AND drift_type = 'CONSECUTIVE'                      -- or 'BASELINE'
  AND column_name = ':table'
  AND COALESCE(slice_key, 'No Slice') = :slice_key
  AND COALESCE(slice_value, 'No Slice') = :slice_value
ORDER BY window.start
```

**Drift Types:**
- `CONSECUTIVE` - Compare to previous period
- `BASELINE` - Compare to baseline window

#### Pattern 3: Distinct Slice Keys (Cascading Filter Source)

```sql
WITH profile_metrics_inspected AS (
  SELECT *
  FROM `{catalog}`.`{schema}_monitoring`.`{table}_profile_metrics`
  WHERE window.start >= :`Time Window Start` 
    AND window.end <= :`Time Window End`
    AND slice_key IS NOT NULL
)
SELECT 'No Slice' AS `Slice Key`
UNION ALL
SELECT DISTINCT slice_key AS `Slice Key`
FROM profile_metrics_inspected
ORDER BY `Slice Key`
```

#### Pattern 4: Distinct Slice Values (Depends on Slice Key)

```sql
WITH profile_metrics_inspected AS (
  SELECT *,
    COALESCE(slice_key, 'No Slice') AS `Slice key`
  FROM `{catalog}`.`{schema}_monitoring`.`{table}_profile_metrics`
  WHERE window.start >= :`Time Window Start` 
    AND window.end <= :`Time Window End`
    AND slice_value IS NOT NULL
)
SELECT 'No Slice' AS `Slice Value`
UNION ALL
SELECT DISTINCT slice_value AS `Slice Value`
FROM profile_metrics_inspected
WHERE `Slice key` = :slice_key
ORDER BY `Slice Value`
```

**Cascading Filter Pattern:**
1. Slice Key filter uses Pattern 3
2. Slice Value filter uses Pattern 4 (depends on selected slice_key)
3. All data datasets filter by both slice_key and slice_value

### Parameter Patterns

#### Time Window Parameters (DATETIME)

**âš ï¸ CRITICAL:** For Lakehouse Monitoring, use `DATETIME` (not `DATE`) with dynamic expressions.

```json
{
  "parameters": [
    {
      "displayName": "Time Window Start",
      "keyword": "Time Window Start",
      "dataType": "DATETIME",
      "defaultSelection": {
        "values": {
          "dataType": "DATETIME",
          "values": [{"value": "now-12M/M"}]  // âœ… Last 12 months
        }
      }
    },
    {
      "displayName": "Time Window End",
      "keyword": "Time Window End",
      "dataType": "DATETIME",
      "defaultSelection": {
        "values": {
          "dataType": "DATETIME",
          "values": [{"value": "now/s"}]  // âœ… Current time
        }
      }
    }
  ]
}
```

**Common Dynamic Date Expressions:**
- `now-12M/M` - Start of 12 months ago
- `now-30d` - 30 days ago
- `now-7d/d` - Start of 7 days ago
- `now/s` - Current second
- `now/d` - Start of today

#### Slice Filter Parameters (STRING)

```json
{
  "parameters": [
    {
      "displayName": "slice_key",
      "keyword": "slice_key",
      "dataType": "STRING",
      "defaultSelection": {
        "values": {
          "dataType": "STRING",
          "values": [{"value": "No Slice"}]  // âœ… Default to no slicing
        }
      }
    },
    {
      "displayName": "slice_value",
      "keyword": "slice_value",
      "dataType": "STRING",
      "defaultSelection": {
        "values": {
          "dataType": "STRING",
          "values": [{"value": "No Slice"}]
        }
      }
    }
  ]
}
```

### Filter Widget Patterns

#### Time Window Filters (Date Pickers)

```json
{
  "widget": {
    "name": "time_start_filter",
    "queries": [
      {"name": "param_dataset1", "query": {
        "datasetName": "dataset1",
        "parameters": [{"name": "Time Window Start", "keyword": "Time Window Start"}],
        "disaggregated": false
      }},
      // ... repeat for all datasets
    ],
    "spec": {
      "encodings": {
        "fields": [
          {"parameterName": "Time Window Start", "queryName": "param_dataset1"},
          // ... repeat for all datasets
        ]
      },
      "frame": {"showTitle": true, "title": "Start Time:"},
      "version": 2,
      "widgetType": "filter-date-picker"
    }
  },
  "position": {"x": 0, "y": 0, "width": 3, "height": 2}
}
```

**Pattern:** Connect filter to ALL datasets that use the parameter.

#### Cascading Slice Filters

**Slice Key Filter (Independent):**

```json
{
  "widget": {
    "name": "slice_key_filter",
    "queries": [
      // Source query for filter options
      {"name": "source_query", "query": {
        "datasetName": "distinct_slice_key",
        "fields": [{"name": "Slice Key", "expression": "`Slice Key`"}],
        "disaggregated": true
      }},
      // Parameter updates for all dependent datasets
      {"name": "param_dataset1", "query": {
        "datasetName": "dataset1",
        "parameters": [{"name": "slice_key", "keyword": "slice_key"}],
        "disaggregated": false
      }},
      {"name": "param_distinct_slice_value", "query": {
        "datasetName": "distinct_slice_value",
        "parameters": [{"name": "slice_key", "keyword": "slice_key"}],
        "disaggregated": false
      }}
      // ... repeat for all datasets
    ],
    "spec": {
      "encodings": {
        "fields": [
          {"displayName": "Slice Key", "fieldName": "Slice Key", "queryName": "source_query"},
          {"parameterName": "slice_key", "queryName": "param_dataset1"},
          {"parameterName": "slice_key", "queryName": "param_distinct_slice_value"}
          // ... repeat
        ]
      },
      "frame": {"showTitle": true, "title": "Slice Key:"},
      "version": 2,
      "widgetType": "filter-single-select"
    }
  },
  "position": {"x": 6, "y": 0, "width": 3, "height": 2}
}
```

**Slice Value Filter (Depends on Slice Key):**

```json
{
  "widget": {
    "name": "slice_value_filter",
    "queries": [
      // Source query (depends on slice_key)
      {"name": "source_query", "query": {
        "datasetName": "distinct_slice_value",  // Uses slice_key parameter!
        "fields": [{"name": "Slice Value", "expression": "`Slice Value`"}],
        "disaggregated": true
      }},
      // Parameter updates for all dependent datasets
      {"name": "param_dataset1", "query": {
        "datasetName": "dataset1",
        "parameters": [{"name": "slice_value", "keyword": "slice_value"}],
        "disaggregated": false
      }}
      // ... repeat for all datasets
    ],
    "spec": {
      "encodings": {
        "fields": [
          {"displayName": "Slice Value", "fieldName": "Slice Value", "queryName": "source_query"},
          {"parameterName": "slice_value", "queryName": "param_dataset1"}
          // ... repeat
        ]
      },
      "frame": {"showTitle": true, "title": "Slice Value:"},
      "version": 2,
      "widgetType": "filter-single-select"
    }
  },
  "position": {"x": 9, "y": 0, "width": 3, "height": 2}
}
```

**Cascading Behavior:**
1. User selects Slice Key â†’ Slice Value options update
2. Slice Value dataset filters by `WHERE \`Slice key\` = :slice_key`
3. All data datasets filter by both parameters

### Visualization Patterns

#### Line Charts for Time Series Trends

```json
{
  "widget": {
    "name": "revenue_chart",
    "queries": [
      {"name": "main_query", "query": {
        "datasetName": "sales_revenue_trend",
        "fields": [
          {"name": "window_start", "expression": "`window_start`"},
          {"name": "total_gross_revenue", "expression": "`total_gross_revenue`"},
          {"name": "total_net_revenue", "expression": "`total_net_revenue`"},
          {"name": "total_return_amount", "expression": "`total_return_amount`"}
        ],
        "disaggregated": true
      }}
    ],
    "spec": {
      "encodings": {
        "x": {
          "axis": {"title": "Time"},
          "displayName": "Window",
          "fieldName": "window_start",
          "scale": {"type": "temporal"}  // âœ… For timestamps
        },
        "y": {
          "fields": [  // âœ… Multiple series
            {"displayName": "Gross Revenue", "fieldName": "total_gross_revenue"},
            {"displayName": "Net Revenue", "fieldName": "total_net_revenue"},
            {"displayName": "Returns", "fieldName": "total_return_amount"}
          ],
          "scale": {"type": "quantitative"}
        }
      },
      "frame": {
        "description": "Track revenue trends over time",
        "showDescription": true,
        "showTitle": true,
        "title": "Revenue Metrics Over Time"
      },
      "version": 3,
      "widgetType": "line"
    }
  },
  "position": {"x": 0, "y": 2, "width": 6, "height": 6}
}
```

**Key Pattern:** Multiple Y-axis series using `fields` array.

#### Tables for Detailed Data

```json
{
  "widget": {
    "name": "sales_aggregate_table",
    "queries": [
      {"name": "main_query", "query": {
        "datasetName": "sales_aggregate_core",
        "disaggregated": true  // âœ… Get all columns
      }}
    ],
    "spec": {
      "version": 1,
      "widgetType": "table",
      "encodings": {
        "columns": [
          {
            "fieldName": "window_start",
            "dateTimeFormat": "DD/MM/YYYY HH:mm:ss.SSS",
            "type": "datetime",
            "displayAs": "datetime",
            "visible": true,
            "order": 0,
            "title": "Window Start"
          },
          {
            "fieldName": "total_gross_revenue",
            "numberFormat": "0.00",  // âœ… 2 decimal places
            "type": "float",
            "displayAs": "number",
            "visible": true,
            "order": 2,
            "title": "Gross Revenue"
          },
          {
            "fieldName": "total_transactions",
            "numberFormat": "0",  // âœ… Integer format
            "type": "integer",
            "displayAs": "number",
            "visible": true,
            "order": 9,
            "title": "Transactions"
          }
          // ... more columns
        ]
      },
      "itemsPerPage": 25,
      "condensed": true,
      "withRowNumber": false
    }
  },
  "position": {"x": 0, "y": 20, "width": 12, "height": 6}
}
```

**Formatting Tips:**
- `numberFormat: "0.00"` - Currency/decimal metrics
- `numberFormat: "0"` - Integer counts
- `dateTimeFormat: "DD/MM/YYYY HH:mm:ss.SSS"` - Timestamps

### Dashboard Layout Pattern

**Standard Monitoring Dashboard Layout:**

```
Row 0-1:  [Time Start Filter] [Time End Filter] [Slice Key Filter] [Slice Value Filter]
          â””â”€ 3 cols wide â”€â”˜ â””â”€ 3 cols wide â”€â”˜  â””â”€ 3 cols wide â”€â”˜  â””â”€ 3 cols wide â”€â”€â”˜

Row 2-7:  [Revenue Chart - 6 cols]  [Volume Chart - 6 cols]

Row 8-13: [KPI Chart - 6 cols]      [Drift Chart - 6 cols]

Row 14-19: [Discount Chart - 6 cols] [Loyalty Chart - 6 cols]

Row 20-25: [Aggregate Metrics Table - 12 cols full width]

Row 26-31: [Derived KPIs Table - 6 cols] [Drift Metrics Table - 6 cols]
```

**Grid System:** 12 columns total (not 6 like standard AI/BI)

**Best Practices:**
- Filters at top (height: 2)
- Charts in middle (height: 6 for standard, 9 for detailed)
- Tables at bottom (height: 6+ for pagination)
- Full-width tables for comprehensive data views

### Complete Dashboard JSON Structure

```json
{
  "datasets": [
    // 4-10 datasets organized by purpose
  ],
  "pages": [
    {
      "name": "sales_page",
      "displayName": "Sales Monitoring - fact_sales_daily",
      "layout": [
        // 4 filter widgets (row 0-1)
        // 2-6 line charts (rows 2-19)
        // 1-3 tables (rows 20-31)
      ],
      "pageType": "PAGE_TYPE_CANVAS"
    }
  ],
  "uiSettings": {
    "theme": {
      "widgetHeaderAlignment": "ALIGNMENT_UNSPECIFIED"
    }
  }
}
```

### Dashboard Creation Checklist

**Dataset Design:**
- [ ] Core aggregate metrics dataset
- [ ] Derived KPIs dataset
- [ ] Data quality metrics dataset (if applicable)
- [ ] Drift metrics dataset
- [ ] Time series datasets for each chart
- [ ] Distinct slice key/value datasets for filters

**Query Patterns:**
- [ ] All profile metrics queries use `log_type = 'INPUT'`
- [ ] All table-level queries use `column_name = ':table'`
- [ ] All queries handle NULL slices with `COALESCE(..., 'No Slice')`
- [ ] Time window filtering with `window.start >= :param`
- [ ] Drift queries use `drift_type = 'CONSECUTIVE'` or 'BASELINE'

**Parameters:**
- [ ] Time Window Start/End use DATETIME with dynamic expressions
- [ ] Slice key/value use STRING with "No Slice" default
- [ ] All datasets connected to relevant parameters

**Filters:**
- [ ] Time window filters (2 date pickers)
- [ ] Slice key filter (connects to slice_value + all datasets)
- [ ] Slice value filter (depends on slice_key)
- [ ] All filters connect to ALL relevant datasets

**Visualizations:**
- [ ] Line charts for trends (x: temporal, y: multiple series)
- [ ] Tables for detailed data (proper formatting)
- [ ] Consistent titles and descriptions
- [ ] Proper number formatting (0.00 for decimals, 0 for integers)

**Layout:**
- [ ] Filters at top (row 0-1, height 2)
- [ ] Charts in middle (height 6)
- [ ] Tables at bottom (height 6+)
- [ ] 12-column grid used correctly

### Troubleshooting Dashboard Issues

#### Issue: "No data" in widgets

**Solutions:**
1. Check `column_name = ':table'` (not per-column filtering)
2. Verify `log_type = 'INPUT'` (not 'OUTPUT')
3. Check time window includes data (`window.start >= :param`)
4. Verify slice filters handle NULL (`COALESCE(..., 'No Slice')`)

#### Issue: Filters don't cascade

**Solution:** Ensure slice_value dataset has slice_key parameter:
```json
{"name": "param_distinct_slice_value", "query": {
  "datasetName": "distinct_slice_value",
  "parameters": [{"name": "slice_key", "keyword": "slice_key"}],
  "disaggregated": false
}}
```

#### Issue: Metrics show NULL values

**Cause:** DERIVED metrics reference AGGREGATE metrics in different `input_columns` row.

**Solution:** Verify all related metrics use `input_columns=[":table"]` in Python monitor definition.

#### Issue: Time window filter doesn't update charts

**Solution:** Connect time window parameters to ALL datasets:
```json
{"name": "param_dataset1", "query": {
  "datasetName": "dataset1",
  "parameters": [
    {"name": "Time Window Start", "keyword": "Time Window Start"},
    {"name": "Time Window End", "keyword": "Time Window End"}
  ],
  "disaggregated": false
}}
```

---

## References

### Official Documentation
- [Lakehouse Monitoring Guide](https://docs.databricks.com/lakehouse-monitoring/)
- [Monitor API Reference](https://docs.databricks.com/api/workspace/qualitymonitors/create)
- [Custom Metrics](https://learn.microsoft.com/azure/databricks/lakehouse-monitoring/custom-metrics)
- [Profile Metrics Table Schema](https://docs.databricks.com/lakehouse-monitoring/monitor-output#profile-metrics-table-schema)
- [Drift Metrics Table Schema](https://docs.databricks.com/lakehouse-monitoring/monitor-output#drift-metrics-table-schema)
- [Column Schemas for Generated Tables](https://docs.databricks.com/lakehouse-monitoring/monitor-output#column-schemas-for-generated-tables) - **Critical for understanding where custom metrics appear**
- [Quality Monitors Update API](https://docs.databricks.com/api/workspace/qualitymonitors/update)
- [Time Series Monitoring Example](https://docs.databricks.com/notebooks/source/monitoring/timeseries-monitor.html)
- [Lakeview AI/BI Dashboards](https://docs.databricks.com/dashboards/)

### Project Implementation
- `src/altria_gold/lakehouse_monitoring.py` - Monitor creation with 144 custom metrics
- `src/altria_gold/monitor_configs.py` - Centralized configuration (pure Python file)
- `src/altria_gold/document_monitoring_tables.py` - Automated documentation
- `src/altria_gold/update_monitors.py` - Safe monitor updates

### Case Studies

#### input_columns Pattern for Table-Level KPIs (October 2025)
**Discovery:** For table-level business KPIs, ALL metrics must use `input_columns=[":table"]`
- Updated 83 AGGREGATE metrics (60 sales + 23 inventory)
- Queries simplified from PIVOT to direct SELECT
- Query performance improved ~40%
- See: `docs/RULE_IMPROVEMENT_INPUT_COLUMNS_PATTERN.md`

#### Custom Metrics as Table Columns (October 2025)
**Discovery:** Custom metrics appear as NEW COLUMNS, not in separate table
- No `custom_metrics` table exists (common misconception)
- AGGREGATE/DERIVED â†’ `profile_metrics` columns
- DRIFT â†’ `drift_metrics` columns
- See: `docs/MONITORING_DOCUMENTATION_ERROR_HANDLING_FIX.md`

---

## Summary

**This comprehensive guide covers:**
1. âœ… Setup & configuration with error handling
2. âœ… Custom metrics design for business KPIs
3. âœ… Query patterns for dashboards
4. âœ… Complete working examples
5. âœ… Troubleshooting common issues

**Key Takeaways:**
- Always use `input_columns=[":table"]` for table-level business KPIs
- Custom metrics appear as NEW COLUMNS (no separate `custom_metrics` table)
- DERIVED metrics can only reference metrics in the same `column_name` row
- Wait 15+ minutes after creation for tables to be ready
- Always update with FULL configuration (never omit custom_metrics)
- Document metrics in `profile_metrics` and `drift_metrics` tables

**Next Steps:**
1. Read setup section for monitor creation
2. Review custom metrics section for metric design
3. Use query patterns for dashboards
4. Follow examples for implementation
5. Reference troubleshooting when issues arise
